[{"path":"/articles/CreatingMigrations.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Creating Migrations","text":"Migrating existing data models can tricky process often creates incompatibility result viewers existing result sets. guide aims show use ResultModelManager class create migrations given result model, either using package file structure. Please see HADES library information HADES packages.","code":""},{"path":"/articles/CreatingMigrations.html","id":"assumptions","dir":"Articles","previous_headings":"","what":"Assumptions","title":"Creating Migrations","text":"package assumes familiar R OHDSI Hades packages general. examples make use DatabaseConnector SqlRender. management data integrity left user, migrations designed tested deployment. Steps maintain data (backup plans) made prior performing migrations case data corruption.","code":""},{"path":"/articles/CreatingMigrations.html","id":"creating-the-required-file-structure","dir":"Articles","previous_headings":"","what":"Creating the required file structure","title":"Creating Migrations","text":"first step creating proper folder structure migrations. chosen path dependent structure used, consistent recommended way expose function within R package allow users upgrade data model. However, flat folder structure require R package installed also supported.","code":""},{"path":"/articles/CreatingMigrations.html","id":"in-an-r-package","dir":"Articles","previous_headings":"Creating the required file structure","what":"In an R package","title":"Creating Migrations","text":"Data migrations exist isolated folder within /inst/sql/ directory package. recommended convention use migrations across Hades package. migrations supported multiple database platforms folder exist within generic (SqlRender OHDSI common sql) sql_server folder, inst/sql/sql_server/migrations. database specific migrations approprate sub directory. example:","code":"inst/sql/     sql_server/migrations/Migration_1-create.sql     sqlite/migrations/Migration_1-create.sql     redshift/migrations/Migration_1-create.sql"},{"path":"/articles/CreatingMigrations.html","id":"using-folder-structure","dir":"Articles","previous_headings":"Creating the required file structure","what":"Using folder structure","title":"Creating Migrations","text":"folder structure requires slightly different set . , migrations split via database platform within migration path. example.","code":"migrations/     sql_server/Migration_1-create.sql     sqlite/Migration_1-create.sql     redshift/Migration_1-create.sql"},{"path":"/articles/CreatingMigrations.html","id":"adding-a-migration","dir":"Articles","previous_headings":"","what":"Adding a migration","title":"Creating Migrations","text":"data migrations assumed OHSI SQL stored within migration folder (see set ). Inside folder migrations conform regular expression (Migration_[0-9]+)-(.+).sql. Explicitly, encodes several things: file migration intended executed DMM instance position sequence migration executed (.e. natural number) string name migration fact sql file example, following file names work: However, following invalid:","code":"Migration_2-MyMigration.sql Migration_2-v3.2whaterver.sql Migration_4-TEST.sql Migration_4-2018922-vAAAA.sql MyMigration.sql # Does not include Migration_1 Migration_2v3.2whaterver.sql # missing - -TEST_Migration_1.sql # Wrong order Migraton_4-a.sql # Migration spelt wrong"},{"path":"/articles/CreatingMigrations.html","id":"adding-migrator","dir":"Articles","previous_headings":"","what":"Adding migrator","title":"Creating Migrations","text":"package/project expose instantiated DMM package specfic considerations. example, package CohortDiagnostics function following may written: return instance data migrator expose teh functionality given data set. Naturally, package strictly required creating migration manager (directory structure conform outline) set according project’s set . Loading migrator straightforward: check migrations valid get status migrations run migrations:","code":"#' @export getDataMigrator <- function(connectionDetails, databaseSchema, tablePrefix) {   ResultModelManager::DataMigrationManager$new(     connectionDetails = connectionDetails,     databaseSchema = databaseSchema,     tablePrefix = tablePrefix,     migrationPath = \"migrations\",     packageName = \"CohortDiagnostics\"   ) } connectionDetails <- DatabaseConnector::createConnectionDetails(MySettings) migrator <- getDataMigrator(connectionDetails = connectionDetails, databaseSchema = \"mySchema\", tablePrefix = \"cd_\") migrator$check() # Will return false and display any eronious files migrator$getStatus() # Will return data frame of all sql migrations and if they have been executed or not ## It is strongly recommended that you create some form of backup before doing this migrator$executeMigrations()"},{"path":"/articles/CreatingMigrations.html","id":"unit-testing","dir":"Articles","previous_headings":"","what":"Unit testing","title":"Creating Migrations","text":"specific advice given write unit tests migrations, however, strongly advised migrations unit tested.","code":""},{"path":"/articles/CreatingMigrations.html","id":"common-issues","dir":"Articles","previous_headings":"","what":"Common issues","title":"Creating Migrations","text":"following list expected issues handling Data migrations:","code":""},{"path":"/articles/CreatingMigrations.html","id":"supporting-all-database-platforms","dir":"Articles","previous_headings":"Common issues","what":"Supporting all database platforms","title":"Creating Migrations","text":"likely challenge support SqlRender/DatabaseConnector supported dbmses. Therefore, careful consideration regards supported platforms made. time writing, results handling, recommend supporting open source platforms SqlRender Postgresql. decision left package author.","code":""},{"path":"/articles/CreatingMigrations.html","id":"sqlite-column-types","dir":"Articles","previous_headings":"Common issues","what":"SQLite column types","title":"Creating Migrations","text":"possible change data type within Sqlite table (ALTER TABLE command work). Consequently, likely rename existing table, create new table modified DDL copy existing data across (using appropriate data transformations/casting). example, changing INT column table foo float requires sqlite specific transformation: ```{sqlite-sql} {DEFAULT @foo = foo} ALTER TABLE @database_schema.@table_prefix@foo RENAME _foo_old; CREATE TABLE @database_schema.@table_prefix@foo ( id bigint, foo float ); INSERT @database_schema.@table_prefix@foo (id, foo) SELECT * _foo_old; ```","code":""},{"path":"/articles/CreatingMigrations.html","id":"non-existent-data","dir":"Articles","previous_headings":"Common issues","what":"Non-existent data","title":"Creating Migrations","text":"presence data model mean data present. packages developed, expected new data formats created. recommended pattern case allow existing data upgraded handle use case missing data downstream reports/web applications.","code":""},{"path":"/articles/ExampleProject.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Example package results spec","text":"guide intends server example using RMM build maintain package produces results end end manner. aspects package cover follows: Creating basic package results specification Using specification create database schema instantiating SQLite database Creating database migration project","code":""},{"path":[]},{"path":"/articles/ExampleProject.html","id":"project-setup","dir":"Articles","previous_headings":"Setup R for data export","what":"Project setup","title":"Example package results spec","text":"First create R package called SimpleFeatureExtractor toy example pulls set aggregate features specified cohorts OMOP CDM exports result set relational database analysis. example export single csv file contains following: Results exported package covariate prevalances related cohorts given covariate_id, related names second table. table saved inst folder R pacakge. Preferably, file called resultsDataModelSpecification.csv package create results csv files correspond fields terms type name.","code":""},{"path":"/articles/ExampleProject.html","id":"creating-a-results-database-schema","dir":"Articles","previous_headings":"Setup R for data export","what":"Creating a results database schema","title":"Example package results spec","text":"First load specification can create schema sql: Viewing sql can see add database_schema parameter executing sql table_prefix need . can easily use create schema using QueryNamespace: Alternatively, can just use DatabaseConnector functions directly.","code":"specification <- ResultModelManager::loadResultsDataModelSpecifications(\"resultsDataModelSpecification\") sql <- ResultModelManager::generateSqlSchema(schemaDefinition = specification) writeLines(sql) ## {DEFAULT @table_prefix = ''} ## {DEFAULT @covariate_definition = covariate_definition} ## {DEFAULT @covariate_result = covariate_result} ##    ## CREATE TABLE @database_schema.@table_prefix@covariate_definition ( ##       covariate_id INT NOT NULL, ##   covariate_name VARCHAR, ##  PRIMARY KEY(covariate_id) ## ); ##   ## CREATE TABLE @database_schema.@table_prefix@covariate_result ( ##       cohort_definition_id INT NOT NULL, ##   covariate_id BIGINT NOT NULL, ##   covariate_mean NUMERIC, ##  PRIMARY KEY(cohort_definition_id,covariate_id) ## ); connectionDetails <- DatabaseConnector::createConnectionDetails(   dbms = \"sqlite\",   server = tempfile() ) qns <- ResultModelManager::createQueryNamespace(   connectionDetails = connectionDetails,   tableSpecification = specification,   tablePrefix = \"my_study_\",   database_schema = \"main\" ) ## Connecting using SQLite driver # note - the table prefix and schema parameters are not neeeded when we do this qns$executeSql(sql) ##   |                                                                              |                                                                      |   0%  |                                                                              |===================================                                   |  50%  |                                                                              |======================================================================| 100% ## Executing SQL took 0.0146 secs connection <- DatabaseConnector::connect(connectionDetails) DatabaseConnector::renderTranslateExecuteSql(connection,   sql,   table_prefix = \"my_study_\",   database_schema = \"main\" )"},{"path":"/articles/ExampleProject.html","id":"uploading-results","dir":"Articles","previous_headings":"Setup R for data export","what":"Uploading results","title":"Example package results spec","text":"Now schema can upload results using functionality exposed package. Using example, results folder following files: results/: can now use results spec upload files (validate conform specification): results uploaded can now write queries inside namespace:","code":"ResultModelManager::uploadResults(connectionDetails,   schema = \"main\",   resultsFolder = \"results\",   tablePrefix = \"my_study_\",   specifications = specification ) qns$queryDb(\"SELECT * FROM @database_schema.@covariate_definition\") ## [1] covariateId   covariateName ## <0 rows> (or 0-length row.names) qns$queryDb(\"SELECT * FROM @database_schema.@covariate_result WHERE cohort_definition_id = @cohort_id\",   cohort_id = 5 ) ## [1] cohortDefinitionId covariateId        covariateMean      ## <0 rows> (or 0-length row.names)"},{"path":"/articles/PackageDesign.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Package Design","text":"ResultModelManager package aims standardize handling data models across OHDSI Hades packages. package designed minimal requirements easily imported others.","code":""},{"path":"/articles/PackageDesign.html","id":"problem-statement","dir":"Articles","previous_headings":"Introduction","what":"Problem statement","title":"Package Design","text":"time writing, OHDSI analytics packages many different specific results data models can change package versions. changes occur data models occurs, old versions dependent software become incompatible new versions. Similarly, applications depend data models encounter changes developers either forced following assumptions: Old results never work new features Old results easily “upgraded” new features bug fixes web applications can’t applied old data users can generate new results - may generated network studies results data models two apps immutable readily changed developers make one-‘hacks’ support fixes legacy results data models results generated different times directly compared without significant time massage data common format Furthermore, Strategus package developed noted many existing analytics packages generate results non standard formats. time data models changed, breaks backwards compatibility.","code":""},{"path":"/articles/PackageDesign.html","id":"package-name","dir":"Articles","previous_headings":"Introduction","what":"Package name","title":"Package Design","text":"Work progress name: ResultModelManager (RMM , phonetically, rum).","code":""},{"path":"/articles/PackageDesign.html","id":"package-purpose","dir":"Articles","previous_headings":"Introduction","what":"Package purpose","title":"Package Design","text":"goal package intended provide common data model utilities can used across OHDSI packages. initial focus handling database migrations via common interface can used within R packages add new data models (existing), handle migrations future versions, report status given data model’s version, get migrations run execute SQL scripts change data model sequential order. addition, common functionality defining querying data models can provided way allows easier access results data models purpose post-collection data analysis. similar function software utility like flyway (used successfully OHDSI WebAPI) - however, geared towards R OHDSI landscape packages, results generated ohdsi analytics packages intended explored using OHDSI open source reporting tools shiny Rmarkdown. analysis - simple expect users install flyway, trivial store handle migrations way.","code":""},{"path":"/articles/PackageDesign.html","id":"scope-and-intended-use","dir":"Articles","previous_headings":"Introduction","what":"Scope and Intended Use","title":"Package Design","text":"package intends provide utilities R Ohdsi packages require exploration results common way. package mainly used OHDSI package maintainers intended users software. Though functionality (alerting users fact data model date) package maintainers implement interfaces provided . terms Data model migrations querying package provide series abstract base classes/interfaces (note: distinction hard enforce within R6) can implemented within individual packages. packages create classes can perform required tasks.","code":""},{"path":[]},{"path":[]},{"path":"/articles/PackageDesign.html","id":"package-dependencies","dir":"Articles","previous_headings":"System Features and Requirements > General","what":"Package dependencies","title":"Package Design","text":"obvious initial dependencies ParrallelLogger, R6, DatabaseConnector SqlRender. Beyond package fairly lightweight require packages outside CRAN. initial requirement package CRAN development conform unless requirement makes impossible.","code":""},{"path":"/articles/PackageDesign.html","id":"data-migration-manager-dmm-class","dir":"Articles","previous_headings":"System Features and Requirements","what":"Data Migration Manager (DMM) Class","title":"Package Design","text":"results migrator class defined R6 class following base functions: Init parameters DatabaseConnector connection connectionDetails object results database schema table prefix Location migration files (e.g. package relative path) load migrations - return data.frame migration file paths order executed status() Get status current data model - return ordered migrations flag haven’t executed check() Check migrations conform standards (can used package tests) executeMigrations() execute migrations completed","code":""},{"path":"/articles/PackageDesign.html","id":"class-definition","dir":"Articles","previous_headings":"System Features and Requirements > Data Migration Manager (DMM) Class","what":"Class definition","title":"Package Design","text":"","code":"DataMigrationManager <- R6::R6Class(   \"DataMigrationManager\",   private = list(     executeMigration = function(filePath) {       # Load, render, translate and execute sql        # Save migration in set of migrations        # Error handling - stop execution, restore transaction     }   ),   public = list(     migrationPath = NULL,     migrationFolder = NULL,     resulultsDatabaseSchema = NULL,     connection = NULL,     initalize = function(connectionDetails,                          resultsDatabaseSchema,                          tablePrefix,                          migrationsPath,                          migrationRegexp = .defaultMigrationRegexp) {       # Set required variables     },     getStatus = function() {       # return data frame all migrations, including file name, order and     },     check = function() {       # Check to see if files follow pattern     },     executeMigrations = function() {       # load list of migrations       # Load list of executed migrations       # if migrations table doesn't exist, create it       # execute migrations that haven't been executed yet     }   ) )"},{"path":"/articles/PackageDesign.html","id":"example-implementation-for-package","dir":"Articles","previous_headings":"System Features and Requirements > Data Migration Manager (DMM) Class","what":"Example implementation for package","title":"Package Design","text":"also possible load manager directory structure outside package. However, may limitations considering way sql files loaded SqlRender, especially including scripts platform specific changes.","code":"#' @inheritParams ResultModelManager::DatabaseMigrationManager - this will probably need to be a factory #' @export` getMigrationManager <- function(migrationsPath = system.file(\"sql\", \"sql_server\", \"migrations\", package = utils::packageName()), ...) {   migrationManager <- ResultModelManager::DatabaseMigrationManager$new(migrationsPath = migrationsPath, ...) }"},{"path":[]},{"path":"/articles/PackageDesign.html","id":"naming-convention","dir":"Articles","previous_headings":"System Features and Requirements > Proposed structure of a migration SQL script","what":"Naming convention","title":"Package Design","text":"data migrations assumed OHSI SQL stored within migration folder. package inst/sql/sql_server/migrations (also likely platform specific, e.g. inst/sql/postgresql/migrations). Inside folder migrations conform regular expression (Migration_[0-9]+)-(.+).sql. Explicitly, encodes several things: file migration intended executed DMM instance position sequence migration executed (.e. natural number) string name migration fact sql file example, following file names work: However, following invalid: check() call within DMM validate . Package/module maintainers also ensure migrations conform adding unit test.","code":"Migration_2-MyMigration.sql Migration_2-v3.2whaterver.sql Migration_4-TEST.sql Migration_4-2018922-vAAAA.sql MyMigration.sql # Does not include Migration_1 Migration_2v3.2whaterver.sql # missing - -TEST_Migration_1.sql # Wrong order Migraton_4-a.sql # Migration spelt wrong"},{"path":"/articles/PackageDesign.html","id":"required-parameters","dir":"Articles","previous_headings":"System Features and Requirements > Proposed structure of a migration SQL script","what":"Required parameters","title":"Package Design","text":"table names variables set using SqlRender parameter {DEFAULT @table_name = my_table_name}. script variables: use @table_prefix referencing tables crucial. However, general use parameters seen necessary time. (NOTE: ’m sure handle parameterized migrations, even desirable. Users can manage DEFAULT keyword SqlRender)","code":"@results_schema @table_prefix"},{"path":"/articles/PackageDesign.html","id":"example-sql","dir":"Articles","previous_headings":"System Features and Requirements > Proposed structure of a migration SQL script","what":"Example SQL","title":"Package Design","text":"","code":"-- changes incidence_rate.person_years from bigint to float {DEFAULT @migration = migration} {DEFAULT @incidence_rate = incidence_rate} {DEFAULT @table_prefix = ''}  ALTER TABLE @results_schema.@table_prefix@incidence_rate ALTER COLUMN person_years FLOAT;"},{"path":"/articles/PackageDesign.html","id":"adding-script-to-list-of-executed-migrations","dir":"Articles","previous_headings":"System Features and Requirements > Proposed structure of a migration SQL script","what":"Adding script to list of executed migrations","title":"Package Design","text":"Following migration following SQL execute: (Note - completed automatically manager class)","code":"INSERT INTO @results_schema.@table_prexif@migration (migration_completed, migration_order)     VALUES ('<fileName>', <order>);"},{"path":"/articles/PackageDesign.html","id":"results-data-model-class","dir":"Articles","previous_headings":"System Features and Requirements","what":"Results Data model class","title":"Package Design","text":"Take connection handle queries pooled non-pooled connections Common getter methods Getting current data model version use shiny apps reporting tools","code":""},{"path":"/articles/PackageDesign.html","id":"utilities","dir":"Articles","previous_headings":"System Features and Requirements","what":"Utilities","title":"Package Design","text":"desirable, hard requirement initial package version, following helper utilities.","code":""},{"path":"/articles/PackageDesign.html","id":"add-migration-function","dir":"Articles","previous_headings":"System Features and Requirements > Utilities","what":"Add migration function","title":"Package Design","text":"provide ability add new migration existing project","code":""},{"path":"/articles/PackageDesign.html","id":"create-ddl-design","dir":"Articles","previous_headings":"System Features and Requirements > Utilities","what":"Create DDL design","title":"Package Design","text":"Function create ddl csv conforms common standards","code":""},{"path":"/articles/PackageDesign.html","id":"create-new-ddl","dir":"Articles","previous_headings":"System Features and Requirements > Utilities","what":"Create new DDL","title":"Package Design","text":"principle added new projects generate results. However, may limited use.","code":""},{"path":"/articles/PackageDesign.html","id":"limitations-and-scope","dir":"Articles","previous_headings":"","what":"Limitations and scope","title":"Package Design","text":"package able support following: New features (e.g. entirely new table) added old results - handling case results exist downstream package migrations existing data models Backup management - utility may support immutable changes data may go wrong. individual organisations manage data backups taking necessary steps mitigate data loss Perform transformations data R software functions - package support data manipulation methods handled R; just structure ddl. manipulations R required, handled package functions. intended manage changes OHDSI vocabularies CDMs!","code":""},{"path":"/articles/UploadFunctionality.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Upload Functionality","text":"vignette describes functionality uploading results pre-created database schema. examples , assume use sqlite simplicity. However, principle platform supported DatabaseConnector SqlRender packages work.","code":""},{"path":"/articles/UploadFunctionality.html","id":"creating-a-schema-definition-file","dir":"Articles","previous_headings":"","what":"Creating a schema definition file","title":"Upload Functionality","text":"recommended every analytics package creates data output contain csv file. requirement packages use OHDSI Strategus library. Schema definitions conform following column headers: addition, packages may make use additional fields optional empty_is_na. required uploading schem. example csv file may look like : Note use sql server data types data_type field well yes binary field is_required primary_key. also define function loading file converts column headers camel case format.","code":"table_name, column_name, data_type, is_required, primary_key # File inst/settings/resulsDataModelSpecifications.csv table_name,column_name,data_type,is_required,primary_key table_1,database_id,varchar,Yes,Yes table_1,analysis_id,bigint,Yes,Yes table_1,analysis_name,varchar,Yes,No table_1,domain_id,varchar(20),No,No table_1,start_day,float,No,No table_1,end_day,float,No,No table_1,is_binary,varchar(1),Yes,No table_1,missing_means_zero,varchar(1),No,No table_2,database_id,varchar,Yes,Yes table_2,analysis2_id,bigint,Yes,Yes table_2,concept_id,int,Yes,No table_2,logic_description,varchar,No,No table_2,valid_start_date,Date,Yes,No table_2,concept_name,varchar(255),Yes,No table_2,p_10_value,float,Yes,No table_3,database_id,varchar,Yes,Yes table_3,analysis3_id,bigint,Yes,Yes table_3,concept_id,int,Yes,No table_3,logic_description,varchar,No,No table_3,valid_start_date,Date,Yes,No table_3,concept_name,varchar(255),Yes,No table_3,p_10_value,float,Yes,No #' Get Results Data Model Specifcations getResultsDataModelSpec <- function() {   # For loading inside an R package   specPath <- system.file(\"settings\", \"resulsDataModelSpecifications.csv\", package = utils::packageName())   spec <- readr::read_csv(specPath, show_col_types = FALSE)   colnames(spec) <- SqlRender::snakeCaseToCamelCase(colnames(spec))   return(spec) }"},{"path":"/articles/UploadFunctionality.html","id":"creating-a-schema","dir":"Articles","previous_headings":"","what":"Creating a schema","title":"Upload Functionality","text":"section describes use RMM create schema specifications file. Note SQL generated generateSqlSchema contains required parameter database_schema optional parameter table_prefix.","code":"connectionDetails <- DatabaseConnector::createConnectionDetails(\"sqlite\", server = \"MySqliteDb.sqlite\") connection <- DatabaseConnector::connect(connectionDetails) sql <- ResultModelManager::generateSqlSchema(schemaDefinition = getResultsDataModelSpec()) DatabaseConnector::renderTranslateExecuteSql(connection, sql, database_schema = \"main\", table_prefix = \"pre_\") DatabaseConnector::disconnect(connection)"},{"path":"/articles/UploadFunctionality.html","id":"uploading-results","dir":"Articles","previous_headings":"","what":"Uploading results","title":"Upload Functionality","text":"section shows upload results conforming specified schema. assumed zip file created csv files corresponding table names provided resulsDataModelSpecifications.csv file. extract zip file upload results using DatabaseConnector. platforms form bulk loading supported, setup contained documentation DatabaseConnector, strongly advised set use functionality platforms store large data sets. However, necessary sqlite example demonstrated .","code":"ResultModelManager::unzipResults(zipFile = \"MyResultsZip.zip\", resultsFolder = \"extraction_folder\") ResultModelManager::uploadResults(connectionDetails,   schema = \"main\",   resultsFolder = \"extraction_folder\",   tablePrefix = \"pre_\",   purgeSiteDataBeforeUploading = FALSE,   specifications = getResultsDataModelSpec() )"},{"path":"/articles/UsingAnExportManager.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Using An Export Manager","text":"OHDSI studies often specific requirements terms exposing patient details.","code":""},{"path":"/articles/UsingAnExportManager.html","id":"creating-the-export-manager-for-a-package","dir":"Articles","previous_headings":"","what":"Creating the export manager for a package","title":"Using An Export Manager","text":"table Specification must definied table exported. Crucially, data types, column names, primary keys valid settings always validated time export. export data conform model, make sure model matches result schema data imported . assumed package developers include unit tests package.","code":"library(ResultModelManager)  tableSpecification <- dplyr::tibble(   tableName = c(     \"my_table\", \"my_table\", \"my_table\", \"my_table\", \"my_table\", \"my_table\", \"my_table\",     \"my_andromeda_table\", \"my_andromeda_table\", \"my_andromeda_table\"   ),   columnName = c(     \"database_id\", \"target_cohort_id\", \"comparator_cohort_id\", \"target_count\", \"comparator_count\", \"rr\", \"p_value\",     \"database_id\", \"covariate_id\", \"value\"   ),   primaryKey = c(     \"yes\", \"yes\", \"no\", \"no\", \"no\", \"no\", \"no\",     \"yes\", \"yes\", \"no\"   ),   minCellCount = c(     \"no\", \"no\", \"no\", \"yes\", \"yes\", \"no\", \"no\",     \"no\", \"no\", \"no\"   ),   dataType = c(     \"varchar(255)\", \"int\", \"int\", \"int\", \"int\", \"float\", \"float\",     \"varchar(255)\", \"bigint\", \"float\"   ) )  # Per database export folder is a good principle to follow exportDir <- \"output_folder/example_cdm\" exportManager <- createResultExportManager(   tableSpecification = tableSpecification,   exportDir = exportDir,   databaseId = \"example_cdm\" )"},{"path":"/articles/UsingAnExportManager.html","id":"saving-large-results-sets-with-a-batch-operation","dir":"Articles","previous_headings":"","what":"Saving large results sets with a batch operation","title":"Using An Export Manager","text":"data sets can easily exceed system memory, operations performed batch (via export manager’s exposed functions callback), exporting Andromeda object.","code":""},{"path":"/articles/UsingAnExportManager.html","id":"setup","dir":"Articles","previous_headings":"Saving large results sets with a batch operation","what":"Setup","title":"Using An Export Manager","text":"First connect test database create test data:","code":"connection <- DatabaseConnector::connect(server = \":memory:\", dbms = \"sqlite\") schema <- \"main\"  # Some made up counts data <- data.frame(   target_cohort_id = 1:100,   comparator_cohort_id = 101:200,   target_count = stats::rpois(100, lambda = 10),   target_time = stats::rpois(100, 100000),   comparator_count = stats::rpois(100, lambda = 5),   comparator_time = stats::rpois(100, 100000) )  DatabaseConnector::insertTable(connection, data = data, tableName = \"result_table\", databaseSchema = schema)"},{"path":"/articles/UsingAnExportManager.html","id":"exporting-a-database-query-result","dir":"Articles","previous_headings":"Saving large results sets with a batch operation","what":"Exporting a database query result","title":"Using An Export Manager","text":"vital ensure returned result set conforms data model, including primary key columns specified. Otherwise, export validation fail prevent errors exported csv files. look file output_folder/example_cdm/my_table.csv notice database_id field populated, add SQL completed per database automatically. Note result set incomplete - ’re exporting fields computed using R function, just values exported sql query.","code":"sql <- \"SELECT * FROM @schema.result_table\" exportManager$exportQuery(connection = connection, sql = sql, exportTableName = \"my_table\", schema = schema)"},{"path":"/articles/UsingAnExportManager.html","id":"performing-r-operations","dir":"Articles","previous_headings":"Saving large results sets with a batch operation > Exporting a database query result","what":"Performing R operations","title":"Using An Export Manager","text":"order perform R operations (example, computing rate ratio p-value difficult compute SQL) recommended performed inside callback function exportQuery method. Modifying include rate ratio calculation using rateratio.test package:","code":"library(rateratio.test)  transformation <- function(rows, pos) {   rrResult <- rateratio.test(     x = c(row$target_count, row$comparator_count),     n = c(row$target_time, row$comparator_time),     RR = 1,     conf.level = 0.95   )    row$rr <- rrResult$estimate   row$p_value <- rrResult$p.value    return(row) }  exportManager$exportQuery(connection,   sql,   \"my_table\",   transformFunction = transformation,   transformFunctionArgs = list(),   append = FALSE,   schema = schema )"},{"path":"/articles/UsingAnExportManager.html","id":"exporting-an-andromeda-result-in-batch","dir":"Articles","previous_headings":"Saving large results sets with a batch operation","what":"Exporting an Andromeda result in batch","title":"Using An Export Manager","text":"generally inadvisable collect entire andromeda table export R session saving disk. Instead, best practice use batch operations follows","code":"andr <- Andromeda::andromeda() andr$my_andromeda_table <- data.frame(covariate_id = 1:1e4, value = stats::runif(1e4))  first <- TRUE writeBatch <- function(batch) {   exportManager$exportDataFrame(batch, \"my_andromeda_table\", append = first)   first <<- FALSE   # we don't want to return anything, just write the result to disk   return(invisible(NULL)) }  Andromeda::batchApply(andr$my_andromeda_table, writeBatch)"},{"path":"/articles/UsingAnExportManager.html","id":"creating-a-results-manifest-file","dir":"Articles","previous_headings":"","what":"Creating a results manifest file","title":"Using An Export Manager","text":"Export manifests contain sha256 hash files exported. can useful see file modified corrupted inclusion. export manifest files within export directory:","code":"exportManger$writeManifest(packageName = \"analytics_package\", packageVersion = packageVersion(\"analytics_package\"))"},{"path":"/articles/UsingConnectionHandlers.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Using Connection Handlers","text":"ConnectionHandler classes R6 instances intent provide consistent manners connect relational database instances top DatabaseConnector utilities. designed long running applications, Plumber APIs Shiny applications generally encapsulated objects (DataMigrationManager).","code":""},{"path":[]},{"path":"/articles/UsingConnectionHandlers.html","id":"creating-an-instance","dir":"Articles","previous_headings":"Basic usage","what":"Creating an instance","title":"Using Connection Handlers","text":"Creating connection handler requires connection details object","code":"connectionDetails <- DatabaseConnector::createConnectionDetails(\"sqlite\", server = \"MyDb.sqlite\") connectionHandler <- ConnectionHandler$new(connectionDetails)"},{"path":"/articles/UsingConnectionHandlers.html","id":"pooled-connections","dir":"Articles","previous_headings":"Basic usage","what":"Pooled connections","title":"Using Connection Handlers","text":"applications Shiny apps require many long running concurrent requests, pooled connections often required. case, polled connection handler used. Instantiation similar : classes behave identically terms queries implement common set functions. See pool::dbPool class information regarding pooled connections.","code":"connectionDetails <- DatabaseConnector::createConnectionDetails(\"sqlite\", server = \"MyDb.sqlite\") connectionHandler <- PooledConnectionHandler$new(connectionDetails)"},{"path":"/articles/UsingConnectionHandlers.html","id":"querying-a-database","dir":"Articles","previous_headings":"Basic usage","what":"Querying a database","title":"Using Connection Handlers","text":"Submitting queries database straightforward uses SqlRender parameterization, example: Similarly, SQL execution can occur Note queries render translate using SqlRender functionality. direct querying execution required functions connectionHander$queryFunction connectionHandler$executeFunction can used, respectively.","code":"result <- connectionHandler$queryDb(\"SELECT * FROM my_table WHERE id = @id\", id = 1) result <- connectionHandler$executeSql(\"CREATE TABLE foo (id INT);\")"},{"path":"/articles/UsingPythonUploads.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Using python for postrgresql uploads","text":"Note, feature considered experimental notice. use DatabaseConnector postgresql without bulk uploads functionality often slow require installation configuration postgresql binaries system. may challenging restrictred many environments. Similarly, method requires writing data.frame disk prohibitively slow data already csv format. consequence, package supports bulk uploading python small amount configuration. uses r-memory; csv files transfered directly python considerably faster process uses psycopg2 python library, can installed via compilation binary form. process demonstrates usage psycopg2-binary package.","code":""},{"path":[]},{"path":"/articles/UsingPythonUploads.html","id":"using-a-virtualenv","dir":"Articles","previous_headings":"Installing psycopg2","what":"Using a virtualenv","title":"Using python for postrgresql uploads","text":"Result model manager provides interactive function enabling python library. psycopg2 function nothing. However, available binary (reticulate package installed) asked install packages. run following: Alternatively can specify manually","code":"ResultModelManager::enablePythonUploads() ResultModelManager::install_psycopg2()"},{"path":"/articles/UsingPythonUploads.html","id":"using-conda-or-system-python-installs","dir":"Articles","previous_headings":"Installing psycopg2","what":"Using conda or system python installs","title":"Using python for postrgresql uploads","text":"Please consult reticulate documentation install psycopg2-binary package.","code":""},{"path":"/articles/UsingPythonUploads.html","id":"usage-within-functions","dir":"Articles","previous_headings":"","what":"Usage within functions","title":"Using python for postrgresql uploads","text":"default, functionality enabled uploading tables function pyUploadCsv fail. enable, directly upload csv, try following example code. Note required call ResultModelManager::enablePythonUploads() every time. alternative, add following line .Renviron file (note automatically assume setup python libraries completed) astute reader realize approach requires IO call, writing CSV disk. many situations major bottleneck. much sensible approach use string buffer. Thankfully, author package provided interface! Note - approach actually already implemented use uploadResults functionality. ’s right - call ResultModelManager::enablePythonUploads() (using postgres) able upload large R data.frames postgres! Better yet, calling ResultModelManager::enablePythonUploads() uploading results OHDSI package automatically give fast(er) upload functionality.","code":"ResultModelManager::enablePythonUploads() connectionDetails <- DabaseConnector::createConnectionDetails(   dbms = \"postgreql\",   server = \"myserver.com\",   port = 5432,   password = \"s\",   user = \"me\",   database = \"some_db\" ) connection <- DatabaseConnector::connect(connectionDetails) readr::write_csv(   data.frame(     id = 1:1e6,     paste(1:1e6, \"bottle(s) on the wall\")   ),   \"my_massive_csv.csv\" )  ResultModelManager::pyUploadCsv(connection,   table = \"my_table\",   filepath = \"my_massive_csv.csv\",   schema = \"my_schema\" ) RMM_USE_PYTHON_UPLOADS=TRUE ResultModelManager::pyUploadDataframe(connection,   table = \"my_table\",   filepath = \"my_massive_csv.csv\",   schema = \"my_schema\" ) ResultModelManager::enablePythonUploads()  ResultModelManager::uploadResults(   connectionDetails,   schema = \"my_schema\",   resultsFolder = \"my_results_folder\",   tablePrefix = \"cm_\",   purgeSiteDataBeforeUploading = FALSE,   specifications = getResultsDataModelSpec() )"},{"path":"/articles/UsingQueryNamespaces.html","id":"purpose","dir":"Articles","previous_headings":"","what":"Purpose","title":"Using Query Namespaces","text":"QueryNamespace class designed convenient way write (re-write) SQL queries packages defined result model specifications. convenience passed parameters must set query - table names pre-defined variables can set result spec reused table prefixes applied tables. intention save time limit bugs. also builds SqlRender/DatabaseConnector principle “Write sql , use anywhere” principle across ohdsi packages. intended replace usage dbplyr style operations expressive allow use sql. However, many find writing SQL strings often convenient portable programming language dplyr calls allow.","code":""},{"path":"/articles/UsingQueryNamespaces.html","id":"basic-usage","dir":"Articles","previous_headings":"","what":"Basic usage","title":"Using Query Namespaces","text":"basic usage create specification single table conforms valid data model specification Note, generally save tables csv file can loaded. load QueryNamespace instance table: can query table sql automatically replaces table names: Note underlying query already handling tablePrefix us, don’t need add :","code":"library(ResultModelManager) ## Loading required package: R6 ## Loading required package: DatabaseConnector tableSpecification <- data.frame(   tableName = \"cohort_definition\",   columnName = c(\"cohort_definition_id\", \"cohort_name\", \"json\", \"sql\"),   primaryKey = c(\"yes\", \"no\", \"no\", \"no\"),   dataType = c(\"bigint\", \"varchar\", \"varchar\", \"varchar\") ) connectionDetails <- DatabaseConnector::createConnectionDetails(\"sqlite\", server = tempfile()) qns <- createQueryNamespace(   connectionDetails = connectionDetails,   usePooledConnection = FALSE,   tableSpecification = tableSpecification,   tablePrefix = \"rwe_study_99_\",   snakeCaseToCamelCase = TRUE,   database_schema = \"main\" ) ## Connecting using SQLite driver # Create our schema within the namespace sql <- generateSqlSchema(schemaDefinition = tableSpecification) # note - the table prefix and schema parameters are not neeeded qns$executeSql(sql) ##   |                                                                              |                                                                      |   0%  |                                                                              |======================================================================| 100% ## Executing SQL took 0.0133 secs qns$queryDb(\"SELECT * FROM @database_schema.@cohort_definition\") ## [1] cohortDefinitionId cohortName         json               sql                ## <0 rows> (or 0-length row.names) qns$queryDb(\"SELECT * FROM @database_schema.@cohort_definition\") ## [1] cohortDefinitionId cohortName         json               sql                ## <0 rows> (or 0-length row.names)"},{"path":"/articles/UsingQueryNamespaces.html","id":"adding-replacement-variables-at-runtime","dir":"Articles","previous_headings":"","what":"Adding replacement variables at runtime","title":"Using Query Namespaces","text":"Variables can naturally added runtime, example, query: Alternatively can persist id object use queries. Note replacing variable result error can also add table specification","code":"qns$queryDb(\"SELECT * FROM @database_schema.@cohort_definition WHERE cohort_definition_id = @id\",   id = 5 ) ## [1] cohortDefinitionId cohortName         json               sql                ## <0 rows> (or 0-length row.names) qns$addReplacementVariable(\"database_id\", \"my_cdm\") qns$addReplacementVariable(\"database_id\", \"my_cdm\") tableSpecification2 <- data.frame(   tableName = \"database_info\",   columnName = c(\"database_id\", \"database_name\"),   primaryKey = c(\"yes\", \"no\"),   dataType = c(\"varchar\", \"varchar\") ) qns$addTableSpecification(tableSpecification2)"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jamie Gilbert. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Gilbert J (2025). ResultModelManager: Result Model Manager. R package version 0.6.0, https://github.com/OHDSI/ResultModelManager.","code":"@Manual{,   title = {ResultModelManager: Result Model Manager},   author = {Jamie Gilbert},   year = {2025},   note = {R package version 0.6.0},   url = {https://github.com/OHDSI/ResultModelManager}, }"},{"path":"/index.html","id":"resultmodelmanager","dir":"","previous_headings":"","what":"Result Model Manager","title":"Result Model Manager","text":"ResultModelManager (RMM) HADES.","code":""},{"path":"/index.html","id":"introduction","dir":"","previous_headings":"","what":"Introduction","title":"Result Model Manager","text":"RMM database data model management utilities R packages Observational Health Data Sciences Informatics program. RMM provides utility functions allow package maintainers migrate existing SQL database models, export import results consistent patterns.","code":""},{"path":"/index.html","id":"system-requirements","dir":"","previous_headings":"","what":"System Requirements","title":"Result Model Manager","text":"Requires R. packages used ResultModelManager require Java.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Result Model Manager","text":"See instructions configuring R environment, including Java. R, use following commands download install ResultModelManager: , install development version:","code":"install.packages(\"ResultModelManager\") remotes::install_github(\"ResultModelManager\", ref = 'develop')"},{"path":"/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Result Model Manager","text":"See articles: - Creating migrations - Example Project - Upload functionality - Connection handler - Using query namespaces","code":""},{"path":"/index.html","id":"support","dir":"","previous_headings":"","what":"Support","title":"Result Model Manager","text":"Developer questions/comments/feedback: OHDSI Forum use GitHub issue tracker bugs/issues/enhancements","code":""},{"path":"/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"Result Model Manager","text":"Read can contribute package.","code":""},{"path":"/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Result Model Manager","text":"ResultModelManager licensed Apache License 2.0","code":""},{"path":"/index.html","id":"development","dir":"","previous_headings":"","what":"Development","title":"Result Model Manager","text":"ResultModelManager developed R Studio.","code":""},{"path":"/index.html","id":"development-status","dir":"","previous_headings":"","what":"Development status","title":"Result Model Manager","text":"Initial release - use care","code":""},{"path":"/reference/ConnectionHandler.html","id":null,"dir":"Reference","previous_headings":"","what":"ConnectionHandler — ConnectionHandler","title":"ConnectionHandler — ConnectionHandler","text":"Class handling DatabaseConnector:connection objects consistent R6 interfaces pooled non-pooled connections. Allows connection cleanly opened closed stored within class/object variables","code":""},{"path":"/reference/ConnectionHandler.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ConnectionHandler — ConnectionHandler","text":"DatabaseConnector Connection instance close Connection boolean TRUE connection valid queryDb boolean TRUE connection valid executeSql","code":""},{"path":"/reference/ConnectionHandler.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"ConnectionHandler — ConnectionHandler","text":"connectionDetails DatabaseConnector connectionDetails object con DatabaseConnector connection object isActive connection active #' snakeCaseToCamelCase (Optional) Boolean. return results columns camel case (default)","code":""},{"path":[]},{"path":"/reference/ConnectionHandler.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"ConnectionHandler — ConnectionHandler","text":"ConnectionHandler$new() ConnectionHandler$dbms() ConnectionHandler$tbl() ConnectionHandler$renderTranslateSql() ConnectionHandler$initConnection() ConnectionHandler$getConnection() ConnectionHandler$closeConnection() ConnectionHandler$dbIsValid() ConnectionHandler$queryDb() ConnectionHandler$executeSql() ConnectionHandler$queryFunction() ConnectionHandler$executeFunction() ConnectionHandler$clone()","code":""},{"path":[]},{"path":"/reference/ConnectionHandler.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ConnectionHandler — ConnectionHandler","text":"","code":"ConnectionHandler$new(   connectionDetails,   loadConnection = TRUE,   snakeCaseToCamelCase = TRUE )"},{"path":"/reference/ConnectionHandler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ConnectionHandler — ConnectionHandler","text":"connectionDetails DatabaseConnector::connectionDetails class loadConnection Boolean option load connection right away snakeCaseToCamelCase (Optional) Boolean. return results columns camel case (default) get dbms","code":""},{"path":"/reference/ConnectionHandler.html","id":"method-dbms-","dir":"Reference","previous_headings":"","what":"Method dbms()","title":"ConnectionHandler — ConnectionHandler","text":"Get dbms type connection get table","code":""},{"path":"/reference/ConnectionHandler.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"ConnectionHandler — ConnectionHandler","text":"","code":"ConnectionHandler$dbms()"},{"path":"/reference/ConnectionHandler.html","id":"method-tbl-","dir":"Reference","previous_headings":"","what":"Method tbl()","title":"ConnectionHandler — ConnectionHandler","text":"get dplyr table object (.e. lazy loaded)","code":""},{"path":"/reference/ConnectionHandler.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"ConnectionHandler — ConnectionHandler","text":"","code":"ConnectionHandler$tbl(table, databaseSchema = NULL)"},{"path":"/reference/ConnectionHandler.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"ConnectionHandler — ConnectionHandler","text":"table table name databaseSchema databaseSchema table belongs Render Translate Sql.","code":""},{"path":"/reference/ConnectionHandler.html","id":"method-rendertranslatesql-","dir":"Reference","previous_headings":"","what":"Method renderTranslateSql()","title":"ConnectionHandler — ConnectionHandler","text":"Masked call SqlRender","code":""},{"path":"/reference/ConnectionHandler.html","id":"usage-3","dir":"Reference","previous_headings":"","what":"Usage","title":"ConnectionHandler — ConnectionHandler","text":"","code":"ConnectionHandler$renderTranslateSql(sql, ...)"},{"path":"/reference/ConnectionHandler.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"ConnectionHandler — ConnectionHandler","text":"sql Sql query string ... Elipsis initConnection","code":""},{"path":"/reference/ConnectionHandler.html","id":"method-initconnection-","dir":"Reference","previous_headings":"","what":"Method initConnection()","title":"ConnectionHandler — ConnectionHandler","text":"Load connection Get Connection","code":""},{"path":"/reference/ConnectionHandler.html","id":"usage-4","dir":"Reference","previous_headings":"","what":"Usage","title":"ConnectionHandler — ConnectionHandler","text":"","code":"ConnectionHandler$initConnection()"},{"path":"/reference/ConnectionHandler.html","id":"method-getconnection-","dir":"Reference","previous_headings":"","what":"Method getConnection()","title":"ConnectionHandler — ConnectionHandler","text":"Returns connection use standard DatabaseConnector calls. Connects automatically yet loaded","code":""},{"path":"/reference/ConnectionHandler.html","id":"usage-5","dir":"Reference","previous_headings":"","what":"Usage","title":"ConnectionHandler — ConnectionHandler","text":"","code":"ConnectionHandler$getConnection()"},{"path":"/reference/ConnectionHandler.html","id":"method-closeconnection-","dir":"Reference","previous_headings":"","what":"Method closeConnection()","title":"ConnectionHandler — ConnectionHandler","text":"Closes connection (active) db Valid","code":""},{"path":"/reference/ConnectionHandler.html","id":"usage-6","dir":"Reference","previous_headings":"","what":"Usage","title":"ConnectionHandler — ConnectionHandler","text":"","code":"ConnectionHandler$closeConnection()"},{"path":"/reference/ConnectionHandler.html","id":"method-dbisvalid-","dir":"Reference","previous_headings":"","what":"Method dbIsValid()","title":"ConnectionHandler — ConnectionHandler","text":"Masks call DBI::dbIsValid. Returns False connection NULL","code":""},{"path":"/reference/ConnectionHandler.html","id":"usage-7","dir":"Reference","previous_headings":"","what":"Usage","title":"ConnectionHandler — ConnectionHandler","text":"","code":"ConnectionHandler$dbIsValid()"},{"path":"/reference/ConnectionHandler.html","id":"method-querydb-","dir":"Reference","previous_headings":"","what":"Method queryDb()","title":"ConnectionHandler — ConnectionHandler","text":"query database return resulting data.frame environment variable LIMIT_ROW_COUNT set Returned rows limited value (default) Limit row count intended web applications may cause denial service consume many resources.","code":""},{"path":"/reference/ConnectionHandler.html","id":"usage-8","dir":"Reference","previous_headings":"","what":"Usage","title":"ConnectionHandler — ConnectionHandler","text":"","code":"ConnectionHandler$queryDb(   sql,   snakeCaseToCamelCase = self$snakeCaseToCamelCase,   overrideRowLimit = FALSE,   ... )"},{"path":"/reference/ConnectionHandler.html","id":"arguments-3","dir":"Reference","previous_headings":"","what":"Arguments","title":"ConnectionHandler — ConnectionHandler","text":"sql sql query string snakeCaseToCamelCase (Optional) Boolean. return results columns camel case (default) overrideRowLimit (Optional) Boolean. cases, row limit enforced system may wish ignore . ... Additional query parameters","code":""},{"path":"/reference/ConnectionHandler.html","id":"method-executesql-","dir":"Reference","previous_headings":"","what":"Method executeSql()","title":"ConnectionHandler — ConnectionHandler","text":"execute set database queries","code":""},{"path":"/reference/ConnectionHandler.html","id":"usage-9","dir":"Reference","previous_headings":"","what":"Usage","title":"ConnectionHandler — ConnectionHandler","text":"","code":"ConnectionHandler$executeSql(sql, ...)"},{"path":"/reference/ConnectionHandler.html","id":"arguments-4","dir":"Reference","previous_headings":"","what":"Arguments","title":"ConnectionHandler — ConnectionHandler","text":"sql sql query string ... Additional query parameters query Function","code":""},{"path":"/reference/ConnectionHandler.html","id":"method-queryfunction-","dir":"Reference","previous_headings":"","what":"Method queryFunction()","title":"ConnectionHandler — ConnectionHandler","text":"queryFunction can overriden subclasses (e.g. use different base function intercept query) translate render sql.","code":""},{"path":"/reference/ConnectionHandler.html","id":"usage-10","dir":"Reference","previous_headings":"","what":"Usage","title":"ConnectionHandler — ConnectionHandler","text":"","code":"ConnectionHandler$queryFunction(   sql,   snakeCaseToCamelCase = self$snakeCaseToCamelCase,   connection = self$getConnection() )"},{"path":"/reference/ConnectionHandler.html","id":"arguments-5","dir":"Reference","previous_headings":"","what":"Arguments","title":"ConnectionHandler — ConnectionHandler","text":"sql sql query string snakeCaseToCamelCase (Optional) Boolean. return results columns camel case (default) connection (Optional) connection object execute Function","code":""},{"path":"/reference/ConnectionHandler.html","id":"method-executefunction-","dir":"Reference","previous_headings":"","what":"Method executeFunction()","title":"ConnectionHandler — ConnectionHandler","text":"exec query Function can overriden subclasses (e.g. use different base function intercept query) translate render sql.","code":""},{"path":"/reference/ConnectionHandler.html","id":"usage-11","dir":"Reference","previous_headings":"","what":"Usage","title":"ConnectionHandler — ConnectionHandler","text":"","code":"ConnectionHandler$executeFunction(sql, connection = self$getConnection())"},{"path":"/reference/ConnectionHandler.html","id":"arguments-6","dir":"Reference","previous_headings":"","what":"Arguments","title":"ConnectionHandler — ConnectionHandler","text":"sql sql query string connection connection object","code":""},{"path":"/reference/ConnectionHandler.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"ConnectionHandler — ConnectionHandler","text":"objects class cloneable method.","code":""},{"path":"/reference/ConnectionHandler.html","id":"usage-12","dir":"Reference","previous_headings":"","what":"Usage","title":"ConnectionHandler — ConnectionHandler","text":"","code":"ConnectionHandler$clone(deep = FALSE)"},{"path":"/reference/ConnectionHandler.html","id":"arguments-7","dir":"Reference","previous_headings":"","what":"Arguments","title":"ConnectionHandler — ConnectionHandler","text":"deep Whether make deep clone.","code":""},{"path":"/reference/DataMigrationManager.html","id":null,"dir":"Reference","previous_headings":"","what":"DataMigrationManager (DMM) — DataMigrationManager","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"R6 class management database migration","code":""},{"path":"/reference/DataMigrationManager.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"data frame migrations, including file name, order execution status Get connection handler","code":""},{"path":[]},{"path":"/reference/DataMigrationManager.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"migrationPath Path migrations exist databaseSchema Path migrations exist packageName packageName, can null tablePrefix tablePrefix, can empty character vector packageTablePrefix packageTablePrefix, can empty character vector","code":""},{"path":[]},{"path":"/reference/DataMigrationManager.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"DataMigrationManager$new() DataMigrationManager$migrationTableExists() DataMigrationManager$getMigrationsPath() DataMigrationManager$getStatus() DataMigrationManager$getConnectionHandler() DataMigrationManager$check() DataMigrationManager$executeMigrations() DataMigrationManager$closeConnection() DataMigrationManager$isPackage() DataMigrationManager$finalize() DataMigrationManager$clone()","code":""},{"path":[]},{"path":"/reference/DataMigrationManager.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"","code":"DataMigrationManager$new(   connectionDetails,   databaseSchema,   tablePrefix = \"\",   packageTablePrefix = \"\",   migrationPath,   packageName = NULL,   migrationRegexp = .defaultMigrationRegexp )"},{"path":"/reference/DataMigrationManager.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"connectionDetails DatabaseConnector connection details object databaseSchema Database Schema execute tablePrefix Optional table prefix tables (e.g. plp, cm, cd etc) packageTablePrefix table prefix used conjunction package results schema, e.g. \"cd_\", \"sccs_\", \"plp_\", \"cm_\" migrationPath Path location migration sql files. package mode, just folder (e.g. \"migrations\") lives location \"sql/sql_server\" () database platforms. folder model, folder must include \"sql_server\" relative path, (e.g  migrationPath = 'migrations' folder 'migrations/sql_server' exists) packageName package mode, name R package migrationRegexp (Optional) regular expression pattern default (Migration_([0-9]+))-(.+).sql Migration table exists","code":""},{"path":"/reference/DataMigrationManager.html","id":"method-migrationtableexists-","dir":"Reference","previous_headings":"","what":"Method migrationTableExists()","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"Check migration table present schema","code":""},{"path":"/reference/DataMigrationManager.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"","code":"DataMigrationManager$migrationTableExists()"},{"path":"/reference/DataMigrationManager.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"boolean Get path migrations","code":""},{"path":"/reference/DataMigrationManager.html","id":"method-getmigrationspath-","dir":"Reference","previous_headings":"","what":"Method getMigrationsPath()","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"Get path sql migration files","code":""},{"path":"/reference/DataMigrationManager.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"","code":"DataMigrationManager$getMigrationsPath(dbms = \"sql server\")"},{"path":"/reference/DataMigrationManager.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"dbms Optionally specify dbms migration fits Get status result model","code":""},{"path":"/reference/DataMigrationManager.html","id":"method-getstatus-","dir":"Reference","previous_headings":"","what":"Method getStatus()","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"Get status migrations (executed )","code":""},{"path":"/reference/DataMigrationManager.html","id":"usage-3","dir":"Reference","previous_headings":"","what":"Usage","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"","code":"DataMigrationManager$getStatus()"},{"path":"/reference/DataMigrationManager.html","id":"method-getconnectionhandler-","dir":"Reference","previous_headings":"","what":"Method getConnectionHandler()","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"Return connection handler instance","code":""},{"path":"/reference/DataMigrationManager.html","id":"usage-4","dir":"Reference","previous_headings":"","what":"Usage","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"","code":"DataMigrationManager$getConnectionHandler()"},{"path":"/reference/DataMigrationManager.html","id":"returns-1","dir":"Reference","previous_headings":"","what":"Returns","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"ConnectionHandler instance Check migrations folder","code":""},{"path":"/reference/DataMigrationManager.html","id":"method-check-","dir":"Reference","previous_headings":"","what":"Method check()","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"Check file names valid migrations Execute Migrations","code":""},{"path":"/reference/DataMigrationManager.html","id":"usage-5","dir":"Reference","previous_headings":"","what":"Usage","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"","code":"DataMigrationManager$check()"},{"path":"/reference/DataMigrationManager.html","id":"method-executemigrations-","dir":"Reference","previous_headings":"","what":"Method executeMigrations()","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"Execute unexecuted migrations","code":""},{"path":"/reference/DataMigrationManager.html","id":"usage-6","dir":"Reference","previous_headings":"","what":"Usage","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"","code":"DataMigrationManager$executeMigrations(stopMigrationVersion = NULL)"},{"path":"/reference/DataMigrationManager.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"stopMigrationVersion (Optional) Migrate specific migration number closeConnection","code":""},{"path":"/reference/DataMigrationManager.html","id":"method-closeconnection-","dir":"Reference","previous_headings":"","what":"Method closeConnection()","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"close connection, active isPackage","code":""},{"path":"/reference/DataMigrationManager.html","id":"usage-7","dir":"Reference","previous_headings":"","what":"Usage","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"","code":"DataMigrationManager$closeConnection()"},{"path":"/reference/DataMigrationManager.html","id":"method-ispackage-","dir":"Reference","previous_headings":"","what":"Method isPackage()","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"package folder structure finalize","code":""},{"path":"/reference/DataMigrationManager.html","id":"usage-8","dir":"Reference","previous_headings":"","what":"Usage","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"","code":"DataMigrationManager$isPackage()"},{"path":"/reference/DataMigrationManager.html","id":"method-finalize-","dir":"Reference","previous_headings":"","what":"Method finalize()","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"Deprecated call, removed future version","code":""},{"path":"/reference/DataMigrationManager.html","id":"usage-9","dir":"Reference","previous_headings":"","what":"Usage","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"","code":"DataMigrationManager$finalize()"},{"path":"/reference/DataMigrationManager.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"objects class cloneable method.","code":""},{"path":"/reference/DataMigrationManager.html","id":"usage-10","dir":"Reference","previous_headings":"","what":"Usage","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"","code":"DataMigrationManager$clone(deep = FALSE)"},{"path":"/reference/DataMigrationManager.html","id":"arguments-3","dir":"Reference","previous_headings":"","what":"Arguments","title":"DataMigrationManager (DMM) — DataMigrationManager","text":"deep Whether make deep clone.","code":""},{"path":"/reference/PooledConnectionHandler.html","id":null,"dir":"Reference","previous_headings":"","what":"Pooled Connection Handler — PooledConnectionHandler","title":"Pooled Connection Handler — PooledConnectionHandler","text":"Transparently works way standard connection handler stores pooled connections. Useful long running applications serve multiple concurrent requests. Note side effect using call increments .GlobalEnv attribute RMMPooledHandlerCount","code":""},{"path":"/reference/PooledConnectionHandler.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pooled Connection Handler — PooledConnectionHandler","text":"boolean TRUE connection valid executeSql","code":""},{"path":"/reference/PooledConnectionHandler.html","id":"super-class","dir":"Reference","previous_headings":"","what":"Super class","title":"Pooled Connection Handler — PooledConnectionHandler","text":"ResultModelManager::ConnectionHandler -> PooledConnectionHandler","code":""},{"path":"/reference/PooledConnectionHandler.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Pooled Connection Handler — PooledConnectionHandler","text":"ResultModelManager::ConnectionHandler$dbIsValid() ResultModelManager::ConnectionHandler$renderTranslateSql() ResultModelManager::ConnectionHandler$tbl()","code":""},{"path":"/reference/PooledConnectionHandler.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Pooled Connection Handler — PooledConnectionHandler","text":"PooledConnectionHandler$new() PooledConnectionHandler$initConnection() PooledConnectionHandler$getCheckedOutConnectionPath() PooledConnectionHandler$getConnection() PooledConnectionHandler$dbms() PooledConnectionHandler$closeConnection() PooledConnectionHandler$queryDb() PooledConnectionHandler$executeSql() PooledConnectionHandler$queryFunction() PooledConnectionHandler$executeFunction() PooledConnectionHandler$clone()","code":""},{"path":[]},{"path":"/reference/PooledConnectionHandler.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pooled Connection Handler — PooledConnectionHandler","text":"","code":"PooledConnectionHandler$new(   connectionDetails = NULL,   snakeCaseToCamelCase = TRUE,   loadConnection = TRUE,   dbConnectArgs = NULL,   forceJdbcConnection = TRUE )"},{"path":"/reference/PooledConnectionHandler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pooled Connection Handler — PooledConnectionHandler","text":"connectionDetails DatabaseConnector::connectionDetails class snakeCaseToCamelCase (Optional) Boolean. return results columns camel case (default) loadConnection Boolean option load connection right away dbConnectArgs Optional arguments call pool::dbPool overrides default usage connectionDetails forceJdbcConnection Force JDBC connection (requires using DatabaseConnector ConnectionDetails) initialize pooled db connection","code":""},{"path":"/reference/PooledConnectionHandler.html","id":"method-initconnection-","dir":"Reference","previous_headings":"","what":"Method initConnection()","title":"Pooled Connection Handler — PooledConnectionHandler","text":"Overrides ConnectionHandler Call Used getting checked connection given environment (one exists)","code":""},{"path":"/reference/PooledConnectionHandler.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Pooled Connection Handler — PooledConnectionHandler","text":"","code":"PooledConnectionHandler$initConnection()"},{"path":[]},{"path":"/reference/PooledConnectionHandler.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Pooled Connection Handler — PooledConnectionHandler","text":"","code":"PooledConnectionHandler$getCheckedOutConnectionPath()"},{"path":"/reference/PooledConnectionHandler.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pooled Connection Handler — PooledConnectionHandler","text":".deferedFrame defaults parent frame calling block. Get Connection","code":""},{"path":"/reference/PooledConnectionHandler.html","id":"method-getconnection-","dir":"Reference","previous_headings":"","what":"Method getConnection()","title":"Pooled Connection Handler — PooledConnectionHandler","text":"Returns connection pool desired frame exits, connection returned pool side effect, connection stored attribute within calling frame (e.g. function) prevent multiple connections spawned, limits performance. call somewhere need think returning object may create connection never returned pool.","code":""},{"path":"/reference/PooledConnectionHandler.html","id":"usage-3","dir":"Reference","previous_headings":"","what":"Usage","title":"Pooled Connection Handler — PooledConnectionHandler","text":"","code":"PooledConnectionHandler$getConnection(.deferedFrame = parent.frame(n = 2))"},{"path":"/reference/PooledConnectionHandler.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pooled Connection Handler — PooledConnectionHandler","text":".deferedFrame defaults parent frame calling block. get dbms","code":""},{"path":"/reference/PooledConnectionHandler.html","id":"method-dbms-","dir":"Reference","previous_headings":"","what":"Method dbms()","title":"Pooled Connection Handler — PooledConnectionHandler","text":"Get dbms type connection Close Connection","code":""},{"path":"/reference/PooledConnectionHandler.html","id":"usage-4","dir":"Reference","previous_headings":"","what":"Usage","title":"Pooled Connection Handler — PooledConnectionHandler","text":"","code":"PooledConnectionHandler$dbms()"},{"path":"/reference/PooledConnectionHandler.html","id":"method-closeconnection-","dir":"Reference","previous_headings":"","what":"Method closeConnection()","title":"Pooled Connection Handler — PooledConnectionHandler","text":"Overrides ConnectionHandler Call - closes active connections called getConnection queryDb","code":""},{"path":"/reference/PooledConnectionHandler.html","id":"usage-5","dir":"Reference","previous_headings":"","what":"Usage","title":"Pooled Connection Handler — PooledConnectionHandler","text":"","code":"PooledConnectionHandler$closeConnection()"},{"path":"/reference/PooledConnectionHandler.html","id":"method-querydb-","dir":"Reference","previous_headings":"","what":"Method queryDb()","title":"Pooled Connection Handler — PooledConnectionHandler","text":"query database return resulting data.frame environment variable LIMIT_ROW_COUNT set Returned rows limited value (default) Limit row count intended web applications may cause denial service consume many resources.","code":""},{"path":"/reference/PooledConnectionHandler.html","id":"usage-6","dir":"Reference","previous_headings":"","what":"Usage","title":"Pooled Connection Handler — PooledConnectionHandler","text":"","code":"PooledConnectionHandler$queryDb(   sql,   snakeCaseToCamelCase = self$snakeCaseToCamelCase,   overrideRowLimit = FALSE,   ... )"},{"path":"/reference/PooledConnectionHandler.html","id":"arguments-3","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pooled Connection Handler — PooledConnectionHandler","text":"sql sql query string snakeCaseToCamelCase (Optional) Boolean. return results columns camel case (default) overrideRowLimit (Optional) Boolean. cases, row limit enforced system may wish ignore . ... Additional query parameters","code":""},{"path":"/reference/PooledConnectionHandler.html","id":"method-executesql-","dir":"Reference","previous_headings":"","what":"Method executeSql()","title":"Pooled Connection Handler — PooledConnectionHandler","text":"execute set database queries","code":""},{"path":"/reference/PooledConnectionHandler.html","id":"usage-7","dir":"Reference","previous_headings":"","what":"Usage","title":"Pooled Connection Handler — PooledConnectionHandler","text":"","code":"PooledConnectionHandler$executeSql(sql, ...)"},{"path":"/reference/PooledConnectionHandler.html","id":"arguments-4","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pooled Connection Handler — PooledConnectionHandler","text":"sql sql query string ... Additional query parameters query Function","code":""},{"path":"/reference/PooledConnectionHandler.html","id":"method-queryfunction-","dir":"Reference","previous_headings":"","what":"Method queryFunction()","title":"Pooled Connection Handler — PooledConnectionHandler","text":"Overrides ConnectionHandler Call. translate render sql.","code":""},{"path":"/reference/PooledConnectionHandler.html","id":"usage-8","dir":"Reference","previous_headings":"","what":"Usage","title":"Pooled Connection Handler — PooledConnectionHandler","text":"","code":"PooledConnectionHandler$queryFunction(   sql,   snakeCaseToCamelCase = self$snakeCaseToCamelCase,   connection )"},{"path":"/reference/PooledConnectionHandler.html","id":"arguments-5","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pooled Connection Handler — PooledConnectionHandler","text":"sql sql query string snakeCaseToCamelCase (Optional) Boolean. return results columns camel case (default) query Function connection db connection assumes pooling handled outside call","code":""},{"path":"/reference/PooledConnectionHandler.html","id":"method-executefunction-","dir":"Reference","previous_headings":"","what":"Method executeFunction()","title":"Pooled Connection Handler — PooledConnectionHandler","text":"Overrides ConnectionHandler Call. translate render sql.","code":""},{"path":"/reference/PooledConnectionHandler.html","id":"usage-9","dir":"Reference","previous_headings":"","what":"Usage","title":"Pooled Connection Handler — PooledConnectionHandler","text":"","code":"PooledConnectionHandler$executeFunction(sql, connection)"},{"path":"/reference/PooledConnectionHandler.html","id":"arguments-6","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pooled Connection Handler — PooledConnectionHandler","text":"sql sql query string connection DatabaseConnector connection. Assumes pooling handled outside call","code":""},{"path":"/reference/PooledConnectionHandler.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Pooled Connection Handler — PooledConnectionHandler","text":"objects class cloneable method.","code":""},{"path":"/reference/PooledConnectionHandler.html","id":"usage-10","dir":"Reference","previous_headings":"","what":"Usage","title":"Pooled Connection Handler — PooledConnectionHandler","text":"","code":"PooledConnectionHandler$clone(deep = FALSE)"},{"path":"/reference/PooledConnectionHandler.html","id":"arguments-7","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pooled Connection Handler — PooledConnectionHandler","text":"deep Whether make deep clone.","code":""},{"path":"/reference/QueryNamespace.html","id":null,"dir":"Reference","previous_headings":"","what":"QueryNamespace — QueryNamespace","title":"QueryNamespace — QueryNamespace","text":"Given results specification ConnectionHandler instance - class allow queries namespaced within tables specified within list pre-determined tables. allows encapsulation queries, using specific table names consistent manner striaghtforward maintain time.","code":""},{"path":"/reference/QueryNamespace.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"QueryNamespace — QueryNamespace","text":"tablePrefix tablePrefix use","code":""},{"path":[]},{"path":"/reference/QueryNamespace.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"QueryNamespace — QueryNamespace","text":"QueryNamespace$new() QueryNamespace$setConnectionHandler() QueryNamespace$getConnectionHandler() QueryNamespace$addReplacementVariable() QueryNamespace$addTableSpecification() QueryNamespace$render() QueryNamespace$queryDb() QueryNamespace$executeSql() QueryNamespace$getVars() QueryNamespace$closeConnection() QueryNamespace$clone()","code":""},{"path":"/reference/QueryNamespace.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"QueryNamespace — QueryNamespace","text":"initialize class","code":""},{"path":"/reference/QueryNamespace.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"QueryNamespace — QueryNamespace","text":"","code":"QueryNamespace$new(   connectionHandler = NULL,   tableSpecification = NULL,   tablePrefix = \"\",   ... )"},{"path":"/reference/QueryNamespace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"QueryNamespace — QueryNamespace","text":"connectionHandler ConnectionHandler instance @seealsoConnectionHandler tableSpecification tableSpecification data.frame tablePrefix constant string prefix tables ... additional replacement variables e.g. database_schema, vocabulary_schema etc Set Connection Handler","code":""},{"path":"/reference/QueryNamespace.html","id":"method-setconnectionhandler-","dir":"Reference","previous_headings":"","what":"Method setConnectionHandler()","title":"QueryNamespace — QueryNamespace","text":"set connection handler object object","code":""},{"path":"/reference/QueryNamespace.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"QueryNamespace — QueryNamespace","text":"","code":"QueryNamespace$setConnectionHandler(connectionHandler)"},{"path":"/reference/QueryNamespace.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"QueryNamespace — QueryNamespace","text":"connectionHandler ConnectionHandler instance Get connection handler","code":""},{"path":"/reference/QueryNamespace.html","id":"method-getconnectionhandler-","dir":"Reference","previous_headings":"","what":"Method getConnectionHandler()","title":"QueryNamespace — QueryNamespace","text":"get connection handler obeject throw error set","code":""},{"path":"/reference/QueryNamespace.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"QueryNamespace — QueryNamespace","text":"","code":"QueryNamespace$getConnectionHandler()"},{"path":"/reference/QueryNamespace.html","id":"method-addreplacementvariable-","dir":"Reference","previous_headings":"","what":"Method addReplacementVariable()","title":"QueryNamespace — QueryNamespace","text":"add variable automatically replaced query strings (e.g. @database_schema.@table_name becomes 'database_schema.table_1')","code":""},{"path":"/reference/QueryNamespace.html","id":"usage-3","dir":"Reference","previous_headings":"","what":"Usage","title":"QueryNamespace — QueryNamespace","text":"","code":"QueryNamespace$addReplacementVariable(key, value, replace = FALSE)"},{"path":"/reference/QueryNamespace.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"QueryNamespace — QueryNamespace","text":"key variable name string (without @) replaced, eg. \"table_name\" value atomic value replacement replace variable key found, overwrite add table specification","code":""},{"path":"/reference/QueryNamespace.html","id":"method-addtablespecification-","dir":"Reference","previous_headings":"","what":"Method addTableSpecification()","title":"QueryNamespace — QueryNamespace","text":"add variable automatically replaced query strings (e.g. @database_schema.@table_name becomes 'database_schema.table_1')","code":""},{"path":"/reference/QueryNamespace.html","id":"usage-4","dir":"Reference","previous_headings":"","what":"Usage","title":"QueryNamespace — QueryNamespace","text":"","code":"QueryNamespace$addTableSpecification(   tableSpecification,   useTablePrefix = TRUE,   tablePrefix = self$tablePrefix,   replace = TRUE )"},{"path":"/reference/QueryNamespace.html","id":"arguments-3","dir":"Reference","previous_headings":"","what":"Arguments","title":"QueryNamespace — QueryNamespace","text":"tableSpecification table specification data.frame conforming column names tableName, columnName, dataType primaryKey useTablePrefix prefix results tablePrefix (TRUE) tablePrefix prefix string - defaults class variable set initialization replace replace existing variables name Render","code":""},{"path":"/reference/QueryNamespace.html","id":"method-render-","dir":"Reference","previous_headings":"","what":"Method render()","title":"QueryNamespace — QueryNamespace","text":"Call SqlRender::render replacing names stored class","code":""},{"path":"/reference/QueryNamespace.html","id":"usage-5","dir":"Reference","previous_headings":"","what":"Usage","title":"QueryNamespace — QueryNamespace","text":"","code":"QueryNamespace$render(sql, ...)"},{"path":"/reference/QueryNamespace.html","id":"arguments-4","dir":"Reference","previous_headings":"","what":"Arguments","title":"QueryNamespace — QueryNamespace","text":"sql query string ... additional variables passed SqlRender::render - overwrite anything namespace query Sql","code":""},{"path":"/reference/QueryNamespace.html","id":"method-querydb-","dir":"Reference","previous_headings":"","what":"Method queryDb()","title":"QueryNamespace — QueryNamespace","text":"Call ","code":""},{"path":"/reference/QueryNamespace.html","id":"usage-6","dir":"Reference","previous_headings":"","what":"Usage","title":"QueryNamespace — QueryNamespace","text":"","code":"QueryNamespace$queryDb(sql, ...)"},{"path":"/reference/QueryNamespace.html","id":"arguments-5","dir":"Reference","previous_headings":"","what":"Arguments","title":"QueryNamespace — QueryNamespace","text":"sql query string ... additional variables send SqlRender::render execute Sql","code":""},{"path":"/reference/QueryNamespace.html","id":"method-executesql-","dir":"Reference","previous_headings":"","what":"Method executeSql()","title":"QueryNamespace — QueryNamespace","text":"Call execute sql within namespaced queries","code":""},{"path":"/reference/QueryNamespace.html","id":"usage-7","dir":"Reference","previous_headings":"","what":"Usage","title":"QueryNamespace — QueryNamespace","text":"","code":"QueryNamespace$executeSql(sql, ...)"},{"path":"/reference/QueryNamespace.html","id":"arguments-6","dir":"Reference","previous_headings":"","what":"Arguments","title":"QueryNamespace — QueryNamespace","text":"sql query string ... additional variables send SqlRender::render get vars","code":""},{"path":"/reference/QueryNamespace.html","id":"method-getvars-","dir":"Reference","previous_headings":"","what":"Method getVars()","title":"QueryNamespace — QueryNamespace","text":"returns full list variables replaced closeConnection","code":""},{"path":"/reference/QueryNamespace.html","id":"usage-8","dir":"Reference","previous_headings":"","what":"Usage","title":"QueryNamespace — QueryNamespace","text":"","code":"QueryNamespace$getVars()"},{"path":"/reference/QueryNamespace.html","id":"method-closeconnection-","dir":"Reference","previous_headings":"","what":"Method closeConnection()","title":"QueryNamespace — QueryNamespace","text":"close connection, active","code":""},{"path":"/reference/QueryNamespace.html","id":"usage-9","dir":"Reference","previous_headings":"","what":"Usage","title":"QueryNamespace — QueryNamespace","text":"","code":"QueryNamespace$closeConnection()"},{"path":"/reference/QueryNamespace.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"QueryNamespace — QueryNamespace","text":"objects class cloneable method.","code":""},{"path":"/reference/QueryNamespace.html","id":"usage-10","dir":"Reference","previous_headings":"","what":"Usage","title":"QueryNamespace — QueryNamespace","text":"","code":"QueryNamespace$clone(deep = FALSE)"},{"path":"/reference/QueryNamespace.html","id":"arguments-7","dir":"Reference","previous_headings":"","what":"Arguments","title":"QueryNamespace — QueryNamespace","text":"deep Whether make deep clone.","code":""},{"path":"/reference/QueryNamespace.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"QueryNamespace — QueryNamespace","text":"","code":"library(ResultModelManager)  # Create some junk test data connectionDetails <-   DatabaseConnector::createConnectionDetails(     server = \"test_db.sqlite\",     dbms = \"sqlite\"   )  conn <- DatabaseConnector::connect(connectionDetails) #> Connecting using SQLite driver DatabaseConnector::insertTable(   connection = conn,   tableName = \"cd_cohort\",   data = data.frame(     cohort_id = c(1, 2, 3),     cohort_name = c(\"cohort one\", \"cohort two\", \"cohort three\"),     json = \"{}\",     sql = \"SELECT 1\"   ) ) #> Inserting data took 0.0112 secs DatabaseConnector::disconnect(conn)  connectionHandler <- ConnectionHandler$new(connectionDetails = connectionDetails) #> Connecting using SQLite driver tableSpecification <- data.frame(   tableName = \"cohort\",   columnName = c(     \"cohort_id\",     \"cohort_name\",     \"json\",     \"sql\"   ),   primaryKey = c(TRUE, FALSE, FALSE, FALSE),   dataType = c(\"int\", \"varchar\", \"varchar\", \"varchar\") )  cohortNamespace <- QueryNamespace$new(   connectionHandler = connectionHandler,   tableSpecification = tableSpecification,   result_schema = \"main\",   tablePrefix = \"cd_\" ) sql <- \"SELECT * FROM @result_schema.@cohort WHERE cohort_id = @cohort_id\" # Returns : \"SELECT * FROM main.cd_cohort WHERE cohort_id = @cohort_id\" print(cohortNamespace$render(sql)) #> [1] \"SELECT * FROM main.cd_cohort WHERE cohort_id = cd_cohort_id\" # Returns query result result <- cohortNamespace$queryDb(sql, cohort_id = 1) # cleanup test data unlink(\"test_db.sqlite\")"},{"path":"/reference/ResultExportManager.html","id":null,"dir":"Reference","previous_headings":"","what":"Result Set Export Manager — ResultExportManager","title":"Result Set Export Manager — ResultExportManager","text":"EXPERIMENTAL - feature still design stage reccomended implement package stage. Utility simplifying export results files sql queries Note utility strictly thread safe though seperate processes can export separate tables without issue. exporting table across multiple threads primary key checks may create issues.","code":""},{"path":"/reference/ResultExportManager.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"Result Set Export Manager — ResultExportManager","text":"exportDir direcotry path export files Init","code":""},{"path":[]},{"path":"/reference/ResultExportManager.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Result Set Export Manager — ResultExportManager","text":"ResultExportManager$new() ResultExportManager$getTableSpec() ResultExportManager$getMinColValues() ResultExportManager$checkRowTypes() ResultExportManager$listTables() ResultExportManager$checkPrimaryKeys() ResultExportManager$exportDataFrame() ResultExportManager$exportQuery() ResultExportManager$getManifestList() ResultExportManager$writeManifest() ResultExportManager$clone()","code":""},{"path":"/reference/ResultExportManager.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Result Set Export Manager — ResultExportManager","text":"Create class exporting results study standard, consistend manner","code":""},{"path":"/reference/ResultExportManager.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Result Set Export Manager — ResultExportManager","text":"","code":"ResultExportManager$new(   tableSpecification,   exportDir,   minCellCount = getOption(\"ohdsi.minCellCount\", default = 5),   validateTypes = FALSE,   usePrimaryKeyCheck = FALSE,   databaseId = NULL )"},{"path":"/reference/ResultExportManager.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Result Set Export Manager — ResultExportManager","text":"tableSpecification Table specification data.frame exportDir Directory files exported minCellCount Minimum cell count - reccomended set options(\"ohdsi.minCellCount\" = count) R projects. Default 5 validateTypes Test row values strictly conform types - optional, currently reccomended outside development usePrimaryKeyCheck Test primary key fields violated export step. - optional, currently reccomended outside development get table spec databaseId database identifier - required exporting according many specs","code":""},{"path":"/reference/ResultExportManager.html","id":"method-gettablespec-","dir":"Reference","previous_headings":"","what":"Method getTableSpec()","title":"Result Set Export Manager — ResultExportManager","text":"Get specification table","code":""},{"path":"/reference/ResultExportManager.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Result Set Export Manager — ResultExportManager","text":"","code":"ResultExportManager$getTableSpec(exportTableName)"},{"path":"/reference/ResultExportManager.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Result Set Export Manager — ResultExportManager","text":"exportTableName table name Get min col values","code":""},{"path":"/reference/ResultExportManager.html","id":"method-getmincolvalues-","dir":"Reference","previous_headings":"","what":"Method getMinColValues()","title":"Result Set Export Manager — ResultExportManager","text":"Columns convert minimum given table name","code":""},{"path":"/reference/ResultExportManager.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Result Set Export Manager — ResultExportManager","text":"","code":"ResultExportManager$getMinColValues(rows, exportTableName)"},{"path":"/reference/ResultExportManager.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"Result Set Export Manager — ResultExportManager","text":"rows data.frame rows exportTableName stering table name - must defined spec Check row types","code":""},{"path":"/reference/ResultExportManager.html","id":"method-checkrowtypes-","dir":"Reference","previous_headings":"","what":"Method checkRowTypes()","title":"Result Set Export Manager — ResultExportManager","text":"Check types rows exporting","code":""},{"path":"/reference/ResultExportManager.html","id":"usage-3","dir":"Reference","previous_headings":"","what":"Usage","title":"Result Set Export Manager — ResultExportManager","text":"","code":"ResultExportManager$checkRowTypes(rows, exportTableName)"},{"path":"/reference/ResultExportManager.html","id":"arguments-3","dir":"Reference","previous_headings":"","what":"Arguments","title":"Result Set Export Manager — ResultExportManager","text":"rows data.frame rows export exportTableName table name List tables","code":""},{"path":"/reference/ResultExportManager.html","id":"method-listtables-","dir":"Reference","previous_headings":"","what":"Method listTables()","title":"Result Set Export Manager — ResultExportManager","text":"list tables schema Check primary keys exported data","code":""},{"path":"/reference/ResultExportManager.html","id":"usage-4","dir":"Reference","previous_headings":"","what":"Usage","title":"Result Set Export Manager — ResultExportManager","text":"","code":"ResultExportManager$listTables()"},{"path":"/reference/ResultExportManager.html","id":"method-checkprimarykeys-","dir":"Reference","previous_headings":"","what":"Method checkPrimaryKeys()","title":"Result Set Export Manager — ResultExportManager","text":"Checks see rows conform valid primary keys table already checked life object set \"invalidateCache\" TRUE keys cached temporary file disk.","code":""},{"path":"/reference/ResultExportManager.html","id":"usage-5","dir":"Reference","previous_headings":"","what":"Usage","title":"Result Set Export Manager — ResultExportManager","text":"","code":"ResultExportManager$checkPrimaryKeys(   rows,   exportTableName,   invalidateCache = FALSE )"},{"path":"/reference/ResultExportManager.html","id":"arguments-4","dir":"Reference","previous_headings":"","what":"Arguments","title":"Result Set Export Manager — ResultExportManager","text":"rows data.frame export exportTableName Table name (must spec) invalidateCache logical - starting fresh export use delete cache primary keys Export data frame","code":""},{"path":"/reference/ResultExportManager.html","id":"method-exportdataframe-","dir":"Reference","previous_headings":"","what":"Method exportDataFrame()","title":"Result Set Export Manager — ResultExportManager","text":"method intended use exporting data.frame query rdbms table example, perform transformation R method check primary keys, min cell counts data types writing file according table spec","code":""},{"path":"/reference/ResultExportManager.html","id":"usage-6","dir":"Reference","previous_headings":"","what":"Usage","title":"Result Set Export Manager — ResultExportManager","text":"","code":"ResultExportManager$exportDataFrame(rows, exportTableName, append = FALSE)"},{"path":"/reference/ResultExportManager.html","id":"arguments-5","dir":"Reference","previous_headings":"","what":"Arguments","title":"Result Set Export Manager — ResultExportManager","text":"rows Rows export exportTableName Table name append logical - true append result file, otherwise file overwritten Export Data table sql query","code":""},{"path":"/reference/ResultExportManager.html","id":"method-exportquery-","dir":"Reference","previous_headings":"","what":"Method exportQuery()","title":"Result Set Export Manager — ResultExportManager","text":"Writes files batch stop overflowing system memory Checks primary keys write Checks minimum cell count","code":""},{"path":"/reference/ResultExportManager.html","id":"usage-7","dir":"Reference","previous_headings":"","what":"Usage","title":"Result Set Export Manager — ResultExportManager","text":"","code":"ResultExportManager$exportQuery(   connection,   sql,   exportTableName,   transformFunction = NULL,   transformFunctionArgs = list(),   append = FALSE,   ... )"},{"path":"/reference/ResultExportManager.html","id":"arguments-6","dir":"Reference","previous_headings":"","what":"Arguments","title":"Result Set Export Manager — ResultExportManager","text":"connection DatabaseConnector connection instance sql OHDSI sql string export tables exportTableName Name table export (snake_case format) transformFunction (optional) transformation data set callback. must take two paramters - rows pos   transformFunctionArgs arguments passed transformation function append Logical add results existing file, FALSE (default) creates new file removes primary key validation cache ... extra parameters passed sql get manifest list","code":"Following this transformation callback, results will be verified against data model,    Primary keys will be checked and minCellValue rules will be enforced"},{"path":"/reference/ResultExportManager.html","id":"method-getmanifestlist-","dir":"Reference","previous_headings":"","what":"Method getManifestList()","title":"Result Set Export Manager — ResultExportManager","text":"Create meta data set collection result files sha256 files","code":""},{"path":"/reference/ResultExportManager.html","id":"usage-8","dir":"Reference","previous_headings":"","what":"Usage","title":"Result Set Export Manager — ResultExportManager","text":"","code":"ResultExportManager$getManifestList(   packageName = NULL,   packageVersion = NULL,   migrationsPath = NULL,   migrationRegexp = .defaultMigrationRegexp )"},{"path":"/reference/ResultExportManager.html","id":"arguments-7","dir":"Reference","previous_headings":"","what":"Arguments","title":"Result Set Export Manager — ResultExportManager","text":"packageName R analysis package, specify name packageVersion analysis package, specify version migrationsPath path sql migrations (use top level folder (e.g. sql/sql_server/migrations) migrationRegexp (optional) regular expression search sql files. reccomended change default. Write manifest","code":""},{"path":"/reference/ResultExportManager.html","id":"method-writemanifest-","dir":"Reference","previous_headings":"","what":"Method writeManifest()","title":"Result Set Export Manager — ResultExportManager","text":"Write manifest json","code":""},{"path":"/reference/ResultExportManager.html","id":"usage-9","dir":"Reference","previous_headings":"","what":"Usage","title":"Result Set Export Manager — ResultExportManager","text":"","code":"ResultExportManager$writeManifest(...)"},{"path":"/reference/ResultExportManager.html","id":"arguments-8","dir":"Reference","previous_headings":"","what":"Arguments","title":"Result Set Export Manager — ResultExportManager","text":"... @seealso getManifestList","code":""},{"path":"/reference/ResultExportManager.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Result Set Export Manager — ResultExportManager","text":"objects class cloneable method.","code":""},{"path":"/reference/ResultExportManager.html","id":"usage-10","dir":"Reference","previous_headings":"","what":"Usage","title":"Result Set Export Manager — ResultExportManager","text":"","code":"ResultExportManager$clone(deep = FALSE)"},{"path":"/reference/ResultExportManager.html","id":"arguments-9","dir":"Reference","previous_headings":"","what":"Arguments","title":"Result Set Export Manager — ResultExportManager","text":"deep Whether make deep clone.","code":""},{"path":"/reference/ResultModelManager-package.html","id":null,"dir":"Reference","previous_headings":"","what":"ResultModelManager: Result Model Manager — ResultModelManager-package","title":"ResultModelManager: Result Model Manager — ResultModelManager-package","text":"Database data model management utilities R packages Observational Health Data Sciences Informatics program https://ohdsi.org. 'ResultModelManager' provides utility functions allow package maintainers migrate existing SQL database models, export import results consistent patterns.","code":""},{"path":[]},{"path":"/reference/ResultModelManager-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"ResultModelManager: Result Model Manager — ResultModelManager-package","text":"Maintainer: Jamie Gilbert gilbert@ohdsi.org","code":""},{"path":"/reference/createQueryNamespace.html","id":null,"dir":"Reference","previous_headings":"","what":"Create query namespace — createQueryNamespace","title":"Create query namespace — createQueryNamespace","text":"Create QueryNamespace instance either connection handler connectionDetails object Allows construction various options handled QueryNamespace$new Note - currently supported multiple table prefixes multiple table namespaces","code":""},{"path":"/reference/createQueryNamespace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create query namespace — createQueryNamespace","text":"","code":"createQueryNamespace(   connectionDetails = NULL,   connectionHandler = NULL,   usePooledConnection = FALSE,   tableSpecification = NULL,   resultModelSpecificationPath = NULL,   tablePrefix = \"\",   snakeCaseToCamelCase = TRUE,   ... )"},{"path":"/reference/createQueryNamespace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create query namespace — createQueryNamespace","text":"connectionDetails object type connectionDetails created using createConnectionDetails function DatabaseConnector package. connectionHandler ResultModelManager ConnectionHandler PooledConnectionHandler instance usePooledConnection Use Pooled database connection instead standard DatabaseConnector single connection. tableSpecification Table specfication data.frame resultModelSpecificationPath (optional) csv file files tableSpecifications - must conform table spec format. tablePrefix String prefix table names - default empty string snakeCaseToCamelCase convert snakecase results camelCase field names (TRUE default) ... Elipsis - use additional string keys replace","code":""},{"path":"/reference/createResultExportManager.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Result Export Manager — createResultExportManager","title":"Create Result Export Manager — createResultExportManager","text":"give table specification file, create export manager instance creating results data sets conform data model. checks , export time, internal validity assured data (e.g. primary keys valid, data types compatible addition utility create manifest object can used maintain validity data. instance DataMigrationManager present available packageVersion reference (applicable) migration set referenced. Allowing data imported database schema specific version.","code":""},{"path":"/reference/createResultExportManager.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Result Export Manager — createResultExportManager","text":"","code":"createResultExportManager(   tableSpecification,   exportDir,   minCellCount = getOption(\"ohdsi.minCellCount\", default = 5),   databaseId = NULL )"},{"path":"/reference/createResultExportManager.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Result Export Manager — createResultExportManager","text":"tableSpecification Table specification data.frame exportDir Directory files exported minCellCount Minimum cell count - reccomended set options(\"ohdsi.minCellCount\" = count) R projects. Default 5 databaseId database identifier - required exporting according many specs","code":""},{"path":"/reference/deleteAllRowsForDatabaseId.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete all rows for database id — deleteAllRowsForDatabaseId","title":"Delete all rows for database id — deleteAllRowsForDatabaseId","text":"Delete rows database id","code":""},{"path":"/reference/deleteAllRowsForDatabaseId.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete all rows for database id — deleteAllRowsForDatabaseId","text":"","code":"deleteAllRowsForDatabaseId(   connection,   schema,   tableName,   databaseId,   idIsInt = TRUE )"},{"path":"/reference/deleteAllRowsForDatabaseId.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete all rows for database id — deleteAllRowsForDatabaseId","text":"connection DatabaseConnector connection instance schema schema postgres server results table exists tableName Database table name databaseId Results source database identifier idIsInt Identified numeric type? character used","code":""},{"path":"/reference/deleteAllRowsForDatabaseId.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Delete all rows for database id — deleteAllRowsForDatabaseId","text":"PostgreSQL servers supported.","code":""},{"path":"/reference/deleteAllRowsForPrimaryKey.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete results rows for primary key values from database server tables — deleteAllRowsForPrimaryKey","title":"Delete results rows for primary key values from database server tables — deleteAllRowsForPrimaryKey","text":"Delete results rows primary key values database server tables","code":""},{"path":"/reference/deleteAllRowsForPrimaryKey.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete results rows for primary key values from database server tables — deleteAllRowsForPrimaryKey","text":"","code":"deleteAllRowsForPrimaryKey(connection, schema, tableName, keyValues)"},{"path":"/reference/deleteAllRowsForPrimaryKey.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete results rows for primary key values from database server tables — deleteAllRowsForPrimaryKey","text":"connection DatabaseConnector connection instance schema schema postgres server results table exists tableName Database table name keyValues Key values results rows deleted","code":""},{"path":"/reference/deleteAllRowsForPrimaryKey.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Delete results rows for primary key values from database server tables — deleteAllRowsForPrimaryKey","text":"PostgreSQL servers supported.","code":""},{"path":"/reference/disablePythonUploads.html","id":null,"dir":"Reference","previous_headings":"","what":"Disable python uploads — disablePythonUploads","title":"Disable python uploads — disablePythonUploads","text":"stop use python uploaResults - work R session. set RMM_USE_PYTHON_UPLOADS .Renviron reset next time start R session.","code":""},{"path":"/reference/disablePythonUploads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Disable python uploads — disablePythonUploads","text":"","code":"disablePythonUploads()"},{"path":"/reference/enablePythonUploads.html","id":null,"dir":"Reference","previous_headings":"","what":"Enable Python Postgres Uploads — enablePythonUploads","title":"Enable Python Postgres Uploads — enablePythonUploads","text":"Step step install enable python uploads","code":""},{"path":"/reference/enablePythonUploads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Enable Python Postgres Uploads — enablePythonUploads","text":"","code":"enablePythonUploads(...)"},{"path":"/reference/enablePythonUploads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Enable Python Postgres Uploads — enablePythonUploads","text":"... parameters pass py_install","code":""},{"path":"/reference/generateSqlSchema.html","id":null,"dir":"Reference","previous_headings":"","what":"Schema generator — generateSqlSchema","title":"Schema generator — generateSqlSchema","text":"Take csv schema definition create basic sql script . returns string containing sql table","code":""},{"path":"/reference/generateSqlSchema.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Schema generator — generateSqlSchema","text":"","code":"generateSqlSchema(   csvFilepath = NULL,   schemaDefinition = NULL,   sqlOutputPath = NULL,   overwrite = FALSE )"},{"path":"/reference/generateSqlSchema.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Schema generator — generateSqlSchema","text":"csvFilepath Path schema file. Csv file must columns: \"table_name\", \"column_name\", \"data_type\", \"primary_key\" schemaDefinition schemaDefintiion data.frame` columns: tableName, columnName, dataType, isRequired, primaryKey sqlOutputPath File write sql . overwrite Boolean - overwrite existing file?","code":""},{"path":"/reference/grantTablePermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Grant Table Permissions — grantTablePermissions","title":"Grant Table Permissions — grantTablePermissions","text":"Grant given permission tables given tableSpecification useful hosting studies data.ohdsi.org postgresql instances NOTE: tested postgresql, users' platforms may Sql translation issues","code":""},{"path":"/reference/grantTablePermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Grant Table Permissions — grantTablePermissions","text":"","code":"grantTablePermissions(   connectionDetails = NULL,   connection = NULL,   tableSpecification,   databaseSchema,   tablePrefix = \"\",   permissions = \"SELECT\",   user )"},{"path":"/reference/grantTablePermissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Grant Table Permissions — grantTablePermissions","text":"connectionDetails object type connectionDetails created using createConnectionDetails function DatabaseConnector package. connection DatabaseConnector connection instance tableSpecification data.frame conforming table spec (must contain tableName field) databaseSchema database schema run tablePrefix String prefix table names - default empty string permissions permissions generate must one SELECT, INSERT, DELETE UPDATE user database user grant permissions ","code":""},{"path":"/reference/install_psycopg2.html","id":null,"dir":"Reference","previous_headings":"","what":"install psycopg2 — install_psycopg2","title":"install psycopg2 — install_psycopg2","text":"Install psycopg2-binary python package specified python virtualenv","code":""},{"path":"/reference/install_psycopg2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"install psycopg2 — install_psycopg2","text":"","code":"install_psycopg2(   envname = Sys.getenv(\"RMM_PYTHON_ENV\", unset = \"rmm-uploads\"),   method = \"auto\",   ... )"},{"path":"/reference/install_psycopg2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"install psycopg2 — install_psycopg2","text":"envname python virtual environment name. Can set system environment variable \"RMM_PYTHON_ENV\", default rmm-uploads method method paramter reticulate::py_install (defualt auto) ... Extra parameters reticulate::py_install","code":""},{"path":"/reference/loadResultsDataModelSpecifications.html","id":null,"dir":"Reference","previous_headings":"","what":"Get specifications from a given file path — loadResultsDataModelSpecifications","title":"Get specifications from a given file path — loadResultsDataModelSpecifications","text":"Get specifications given file path","code":""},{"path":"/reference/loadResultsDataModelSpecifications.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get specifications from a given file path — loadResultsDataModelSpecifications","text":"","code":"loadResultsDataModelSpecifications(filePath)"},{"path":"/reference/loadResultsDataModelSpecifications.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get specifications from a given file path — loadResultsDataModelSpecifications","text":"filePath path valid csv file","code":""},{"path":"/reference/loadResultsDataModelSpecifications.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get specifications from a given file path — loadResultsDataModelSpecifications","text":"tibble data frame object specifications","code":""},{"path":"/reference/pyPgUploadEnabled.html","id":null,"dir":"Reference","previous_headings":"","what":"are python postgresql uploads enabled? — pyPgUploadEnabled","title":"are python postgresql uploads enabled? — pyPgUploadEnabled","text":"python postgresql uploads enabled?","code":""},{"path":"/reference/pyPgUploadEnabled.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"are python postgresql uploads enabled? — pyPgUploadEnabled","text":"","code":"pyPgUploadEnabled()"},{"path":"/reference/pyUploadCsv.html","id":null,"dir":"Reference","previous_headings":"","what":"Py Upload CSV — pyUploadCsv","title":"Py Upload CSV — pyUploadCsv","text":"Wrapper python function upload csv using Postgres Copy functionality","code":""},{"path":"/reference/pyUploadCsv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Py Upload CSV — pyUploadCsv","text":"","code":"pyUploadCsv(connection, table, filepath, schema, disableConstraints = FALSE)"},{"path":"/reference/pyUploadCsv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Py Upload CSV — pyUploadCsv","text":"connection DatabaseConnector connection instance table Table database filepath path csv schema database schema containing table reference disableConstraints (reccomended) disable constraints prior upload speed process","code":""},{"path":"/reference/pyUploadCsv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Py Upload CSV — pyUploadCsv","text":"","code":"if (FALSE) { # \\dontrun{ connection <- DabaseConnector::connect(   dbms = \"postgreql\",   server = \"myserver.com\",   port = 5432,   password = \"s\",   user = \"me\",   database = \"some_db\" ) ResultModelManager::pyUploadCsv(connection,   table = \"my_table\",   filepath = \"my_massive_csv.csv\",   schema = \"my_schema\" ) } # }"},{"path":"/reference/pyUploadDataFrame.html","id":null,"dir":"Reference","previous_headings":"","what":"Py Upload data.frame — pyUploadDataFrame","title":"Py Upload data.frame — pyUploadDataFrame","text":"Wrapper python function upload data.frame using Postgres Copy functionality","code":""},{"path":"/reference/pyUploadDataFrame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Py Upload data.frame — pyUploadDataFrame","text":"","code":"pyUploadDataFrame(data, connection, table, schema)"},{"path":"/reference/pyUploadDataFrame.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Py Upload data.frame — pyUploadDataFrame","text":"data data.frame connection DatabaseConnector connection instance table Table database schema database schema containing table reference","code":""},{"path":"/reference/pyUploadDataFrame.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Py Upload data.frame — pyUploadDataFrame","text":"","code":"if (FALSE) { # \\dontrun{ connection <- DabaseConnector::connect(   dbms = \"postgreql\",   server = \"myserver.com\",   port = 5432,   password = \"s\",   user = \"me\",   database = \"some_db\" )  ResultModelManager::pyUploadDataFrame(connection,   table = \"my_table\",   data.frame(id = 1:100, value = \"some_value\"),   schema = \"my_schema\" ) } # }"},{"path":"/reference/unzipResults.html","id":null,"dir":"Reference","previous_headings":"","what":"Unzips a results.zip file and enforces standards required by uploadResults — unzipResults","title":"Unzips a results.zip file and enforces standards required by uploadResults — unzipResults","text":"function unzip zipFile resultsFolder assert file resultsDataModelSpecification.csv exists resultsFolder ensure work uploadResults","code":""},{"path":"/reference/unzipResults.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unzips a results.zip file and enforces standards required by uploadResults — unzipResults","text":"","code":"unzipResults(zipFile, resultsFolder)"},{"path":"/reference/unzipResults.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unzips a results.zip file and enforces standards required by uploadResults — unzipResults","text":"zipFile location .zip file holds results upload resultsFolder folder use unzipping .zip file. folder exist, function attempt create folder.","code":""},{"path":"/reference/uploadResults.html","id":null,"dir":"Reference","previous_headings":"","what":"Upload results to the database server. — uploadResults","title":"Upload results to the database server. — uploadResults","text":"Requires results data model tables created using following specifications, generateSqlSchema function. Results files snake_case format table headers camelCase Set POSTGRES_PATH environmental variable path folder containing psql executable enable bulk upload (recommended).","code":""},{"path":"/reference/uploadResults.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Upload results to the database server. — uploadResults","text":"","code":"uploadResults(   connection = NULL,   connectionDetails = NULL,   schema,   resultsFolder,   tablePrefix = \"\",   forceOverWriteOfSpecifications = FALSE,   purgeSiteDataBeforeUploading = TRUE,   databaseIdentifierFile = \"cdm_source_info.csv\",   runCheckAndFixCommands = FALSE,   warnOnMissingTable = TRUE,   purgeDataModel = FALSE,   specifications )"},{"path":"/reference/uploadResults.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Upload results to the database server. — uploadResults","text":"connection object type connection created using connect function DatabaseConnector package. Can left NULL connectionDetails provided, case new connection opened start function, closed function finishes. connectionDetails object type connectionDetails created using createConnectionDetails function DatabaseConnector package. schema schema postgres server tables created. resultsFolder path folder containing results upload. See unzipResults information. tablePrefix String prefix table names - default empty string forceOverWriteOfSpecifications TRUE, specifications phenotypes, cohort definitions, analysis overwritten already exist database. use specifications changed since last upload. purgeSiteDataBeforeUploading TRUE, inserting data specific databaseId data site dropped. assumes results folder contains full data data site. databaseIdentifierFile File contained references databaseId field (used purgeSiteDataBeforeUploading == TRUE). may specify relative path cdmSourceFile function assume resides resultsFolder. Alternatively, can provide path outside resultsFolder file. runCheckAndFixCommands TRUE, upload code attempt fix column names, data types duplicate rows. parameter kept legacy reasons - strongly recommended correct errors results results assembled instead relying option try fix upload. warnOnMissingTable Boolean, print warning table file missing. purgeDataModel function purge data tables specification prior upload. Use care. interactive require input. specifications tibble data frame object specifications.","code":""},{"path":"/news/index.html","id":"resultmodelmanager-060","dir":"Changelog","previous_headings":"","what":"ResultModelManager 0.6.0","title":"ResultModelManager 0.6.0","text":"Changes: Added experimental wrapper functions python based upload csv files Breaking change - public use finalize R6 classes causes deprecation warning use R6 package. Package maintainers replace class closeConnection use added classes. Note - due CRAN package release without making change. Bug Fixes: Fixed big type check issue ResultExportManager Fixed bad deletion existing primary key rows. Also improved efficiency delete using join","code":""},{"path":"/news/index.html","id":"resultmodelmanager-0511","dir":"Changelog","previous_headings":"","what":"ResultModelManager 0.5.11","title":"ResultModelManager 0.5.11","text":"CRAN release: 2024-09-19 Changes: Refactor tests accommodate cran","code":""},{"path":"/news/index.html","id":"resultmodelmanager-0510","dir":"Changelog","previous_headings":"","what":"ResultModelManager 0.5.10","title":"ResultModelManager 0.5.10","text":"CRAN release: 2024-08-21 Changes: Using readr column types work around issues inconsistent type conversion DBI JDBC drivers. Bug fixes: Resolved issue failed queries aborted inside wrong connection PooledConnectionHandler Refactored pooled connection handler better ensure checkout connections returned","code":""},{"path":"/news/index.html","id":"resultmodelmanager-059","dir":"Changelog","previous_headings":"","what":"ResultModelManager 0.5.9","title":"ResultModelManager 0.5.9","text":"CRAN release: 2024-07-21 Changes: tidy cleanup PooledConnectionHandlers prevent leaked connections.","code":""},{"path":"/news/index.html","id":"resultmodelmanager-059-1","dir":"Changelog","previous_headings":"","what":"ResultModelManager 0.5.9","title":"ResultModelManager 0.5.9","text":"CRAN release: 2024-07-21 Changes: Changes made make package CRAN compliant PooledConnectionHandler now uses withr::defer automatically returned pooled connections returned getConnection","code":""},{"path":"/news/index.html","id":"resultmodelmanager-058","dir":"Changelog","previous_headings":"","what":"ResultModelManager 0.5.8","title":"ResultModelManager 0.5.8","text":"Bug fixes: Fixed bug uploads empty tables used determine uploads (can fail)","code":""},{"path":"/news/index.html","id":"resultmodelmanager-057","dir":"Changelog","previous_headings":"","what":"ResultModelManager 0.5.7","title":"ResultModelManager 0.5.7","text":"Bug fixes: Added type conversion checking upload data columns characters interpreted numeric reading inserted data","code":""},{"path":"/news/index.html","id":"resultmodelmanager-056","dir":"Changelog","previous_headings":"","what":"ResultModelManager 0.5.6","title":"ResultModelManager 0.5.6","text":"Changes: PooledConnectionHandler, added check see java stack size set unix systems connecting stop overflow errors rconnect platforms. Note solution fail RJava called connection","code":""},{"path":"/news/index.html","id":"resultmodelmanager-055","dir":"Changelog","previous_headings":"","what":"ResultModelManager 0.5.5","title":"ResultModelManager 0.5.5","text":"Bug Fixes: 1. Removal comment DataMigrationManager sql caused translation error spark/databricks platforms “optional” column model specification now fully optional (present, columns assumed required)","code":""},{"path":"/news/index.html","id":"resultmodelmanager-054","dir":"Changelog","previous_headings":"","what":"ResultModelManager 0.5.4","title":"ResultModelManager 0.5.4","text":"Changes: Use jdbc connection default pooled connection class","code":""},{"path":"/news/index.html","id":"resultmodelmanager-053","dir":"Changelog","previous_headings":"","what":"ResultModelManager 0.5.3","title":"ResultModelManager 0.5.3","text":"Changes: Tests PooledConnection classes Bug Fixes: Use RPostgres updated. Use dbplyr::in_schema using dplyr::tbl ConnectionHandlers","code":""},{"path":"/news/index.html","id":"resultmodelmanager-052","dir":"Changelog","previous_headings":"","what":"ResultModelManager 0.5.2","title":"ResultModelManager 0.5.2","text":"Changes: Allow PooledConnectionHandler classes use DBI connections bypass use JDBC systems may supported. Bug Fixes: Fixed issue platform specific migrations SqlRender sometimes fails add attribute calling loadRenderTranslateSql","code":""},{"path":"/news/index.html","id":"resultmodelmanager-051","dir":"Changelog","previous_headings":"","what":"ResultModelManager 0.5.1","title":"ResultModelManager 0.5.1","text":"Bug fixes: Fixed issue uploads results removal emptyIsNa property longer used/required","code":""},{"path":"/news/index.html","id":"resultmodelmanager-050","dir":"Changelog","previous_headings":"","what":"ResultModelManager 0.5.0","title":"ResultModelManager 0.5.0","text":"Changes: 1. Added utility function grantTablePermissions make easier grant select, delete, insert update permissions users results database setups Added ResultExportManager class utility support standardized validation routines exported data Allow packages internal migration table prefix separate user defined one e.g my_study_sccs_migration emptyIsNa field longer required specifications Purge data supported upload functionality (requiring user input) Bug fixes: generateSqlSchema longer requires primary key field lower case results spec files, now case-insensitive connectionHandlers now check sql string attribute see query needs translating, avoiding potential errors caused double translation","code":""},{"path":"/news/index.html","id":"resultmodelmanager-040","dir":"Changelog","previous_headings":"","what":"ResultModelManager 0.4.0","title":"ResultModelManager 0.4.0","text":"Changes: removed spuriously added createResultsDataModel function added QueryNamespace R6 class allows users define table specification complete queries without always specify table names Added createQueryNamespace helper function allow variety convenient ways create query namespaces Added loadResultsDataModelSpecifications loads results specs csv file checks columns correct Added vignettes usage package features","code":""},{"path":"/news/index.html","id":"resultmodelmanager-030","dir":"Changelog","previous_headings":"","what":"ResultModelManager 0.3.0","title":"ResultModelManager 0.3.0","text":"Changes: Added support validating results model schema data.frames Added function generate sql creating schemas specification data frames Added unzip folder function Added robust upload function directories csv files conforming model specifications Added vignette describe creating results schemas uploading data sets","code":""},{"path":"/news/index.html","id":"resultmodelmanager-020","dir":"Changelog","previous_headings":"","what":"ResultModelManager 0.2.0","title":"ResultModelManager 0.2.0","text":"Changes: Fixed support newer versions DatabaseConnector altered interface - mean package now depends DatabaseConnector version 6.0.0 . However, queryDb compatibility means code uses classes need altered. Added support ConnectionHandler load tables dbplyr/dplyr tbl interface (.e. lazy loading). means dplyr style queries supported natively Pooled non-pooled connections.","code":""},{"path":"/news/index.html","id":"resultmodelmanager-011","dir":"Changelog","previous_headings":"","what":"ResultModelManager 0.1.1","title":"ResultModelManager 0.1.1","text":"Changes: 1. Added snakeCaseToCamelCase parameter public connectionHandlers can defined required Added schema generator function creates sql csv files table defs","code":""},{"path":"/news/index.html","id":"resultmodelmanager-010","dir":"Changelog","previous_headings":"","what":"ResultModelManager 0.1.0","title":"ResultModelManager 0.1.0","text":"Initial version","code":""}]
